{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+BLjKpZVx4hlBPU6aR1F3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reetu9696/Breast-Cancer-Detection/blob/main/Breast_Cancer_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9rX3pT9w9-Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad357474"
      },
      "source": [
        "# Task\n",
        "Design a comprehensive breast cancer detection system that utilizes patient details, medical reports, and a multilingual voice assistant nurse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa814c12"
      },
      "source": [
        "## Define data sources and types\n",
        "\n",
        "### Subtask:\n",
        "Identify the specific types of patient data and reports that will be used, including structured (e.g., age, family history) and unstructured data (e.g., doctor's notes, voice recordings).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbc285aa"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires listing and describing structured and unstructured data types relevant to breast cancer detection. This can be done by creating lists and descriptions in a code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5edbd10",
        "outputId": "4c6eb172-47a1-45b4-8aa2-4bcda81120f9"
      },
      "source": [
        "# 1. Structured Data Points\n",
        "structured_data = {\n",
        "    \"Age\": \"Increased age is a significant risk factor for breast cancer.\",\n",
        "    \"Gender\": \"While both men and women can get breast cancer, it is far more common in women.\",\n",
        "    \"Family History of Cancer\": \"A personal or family history of breast cancer or certain other cancers increases risk.\",\n",
        "    \"Previous Biopsies\": \"Having had a previous breast biopsy, especially if atypical cells were found, can increase risk.\",\n",
        "    \"Hormonal Factors\": \"Factors like early menstruation, late menopause, and hormone replacement therapy can influence risk.\",\n",
        "    \"Lifestyle Choices\": \"Smoking, alcohol consumption, obesity, and lack of physical activity are associated with increased risk.\"\n",
        "}\n",
        "\n",
        "# 2. Unstructured Data Types\n",
        "unstructured_data = {\n",
        "    \"Doctor's Notes\": \"Can provide subjective observations, patient-reported symptoms, and details not captured in structured fields.\",\n",
        "    \"Pathology Reports\": \"Contain detailed microscopic descriptions of tissue samples, crucial for diagnosis and classification.\",\n",
        "    \"Radiology Reports\": \"Describe findings from imaging tests like mammograms, ultrasounds, and MRIs, essential for identifying suspicious areas.\",\n",
        "    \"Audio Recordings of Patient-Voice Assistant Interactions\": \"Can capture patient concerns, symptom descriptions in their own words, and potentially emotional state.\"\n",
        "}\n",
        "\n",
        "# 3. Print the data types and their relevance\n",
        "print(\"Structured Data Points and their Relevance:\")\n",
        "for data_point, relevance in structured_data.items():\n",
        "    print(f\"- {data_point}: {relevance}\")\n",
        "\n",
        "print(\"\\nUnstructured Data Types and their Relevance:\")\n",
        "for data_type, relevance in unstructured_data.items():\n",
        "    print(f\"- {data_type}: {relevance}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured Data Points and their Relevance:\n",
            "- Age: Increased age is a significant risk factor for breast cancer.\n",
            "- Gender: While both men and women can get breast cancer, it is far more common in women.\n",
            "- Family History of Cancer: A personal or family history of breast cancer or certain other cancers increases risk.\n",
            "- Previous Biopsies: Having had a previous breast biopsy, especially if atypical cells were found, can increase risk.\n",
            "- Hormonal Factors: Factors like early menstruation, late menopause, and hormone replacement therapy can influence risk.\n",
            "- Lifestyle Choices: Smoking, alcohol consumption, obesity, and lack of physical activity are associated with increased risk.\n",
            "\n",
            "Unstructured Data Types and their Relevance:\n",
            "- Doctor's Notes: Can provide subjective observations, patient-reported symptoms, and details not captured in structured fields.\n",
            "- Pathology Reports: Contain detailed microscopic descriptions of tissue samples, crucial for diagnosis and classification.\n",
            "- Radiology Reports: Describe findings from imaging tests like mammograms, ultrasounds, and MRIs, essential for identifying suspicious areas.\n",
            "- Audio Recordings of Patient-Voice Assistant Interactions: Can capture patient concerns, symptom descriptions in their own words, and potentially emotional state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29c497dd"
      },
      "source": [
        "## Develop data collection and preprocessing strategy\n",
        "\n",
        "### Subtask:\n",
        "Outline how the data will be collected, cleaned, and preprocessed for use in a machine learning model. This includes handling missing values, standardizing formats, and extracting relevant features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a550c55"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the data collection, cleaning, and preprocessing steps for both structured and unstructured data as outlined in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55a800b",
        "outputId": "80c6cf89-1ca9-4117-a602-ef6b02797dc5"
      },
      "source": [
        "# 1. Data Collection\n",
        "print(\"1. Data Collection:\")\n",
        "print(\"Structured Data: Collected from electronic health records (EHRs), patient intake forms, and potentially patient surveys. Methods include database queries and API integrations with EHR systems.\")\n",
        "print(\"Unstructured Data: Collected from medical imaging systems (Radiology Reports), laboratory information systems (Pathology Reports), transcription of doctor's notes, and the multilingual voice assistant nurse recordings.\")\n",
        "\n",
        "# 2. Cleaning Structured Data\n",
        "print(\"\\n2. Cleaning Structured Data:\")\n",
        "print(\"- Handling Missing Values: Missing numerical data (e.g., age) can be imputed using mean, median, or regression imputation. Missing categorical data (e.g., family history) can be imputed using mode or by creating a 'missing' category. Alternatively, rows with a high percentage of missing values for critical features might be removed.\")\n",
        "print(\"- Identifying and Correcting Inconsistencies: Data validation rules can be applied to ensure data is within expected ranges (e.g., age between 0 and 120). Inconsistent categorical entries (e.g., different spellings of the same condition) can be standardized using mapping or lookup tables.\")\n",
        "print(\"- Addressing Outliers: Outliers in numerical data can be identified using methods like Z-scores or IQR and handled by capping, transformation, or removal, depending on the analysis's sensitivity to extreme values.\")\n",
        "\n",
        "# 3. Preprocessing Unstructured Data\n",
        "print(\"\\n3. Preprocessing Unstructured Data:\")\n",
        "print(\"Text Data (Doctor's Notes, Pathology Reports, Radiology Reports):\")\n",
        "print(\"-- Tokenization: Breaking down text into individual words or sub-word units.\")\n",
        "print(\"-- Lowercasing: Converting all text to lowercase for consistency.\")\n",
        "print(\"-- Removing Stop Words: Eliminating common words that do not carry significant meaning (e.g., 'the', 'a', 'is').\")\n",
        "print(\"-- Stemming or Lemmatization: Reducing words to their root form.\")\n",
        "print(\"-- Vectorization: Converting text into numerical representations using techniques like TF-IDF, Word2Vec, or BERT embeddings.\")\n",
        "print(\"Audio Data (Audio Recordings of Patient-Voice Assistant Interactions):\")\n",
        "print(\"-- Noise Reduction: Applying filters to minimize background noise.\")\n",
        "print(\"-- Silence Removal: Removing periods of silence.\")\n",
        "print(\"-- Feature Extraction: Extracting relevant features like Mel-Frequency Cepstral Coefficients (MFCCs), pitch, and energy.\")\n",
        "\n",
        "# 4. Feature Extraction and Engineering\n",
        "print(\"\\n4. Feature Extraction and Engineering:\")\n",
        "print(\"Structured Data: Categorical features (e.g., Gender, Family History of Cancer) can be converted into numerical format using one-hot encoding.\")\n",
        "print(\"Unstructured Data: The numerical representations from text and audio preprocessing (e.g., TF-IDF vectors, embeddings, MFCCs) serve as features. Dimensionality reduction techniques like PCA or t-SNE might be applied to high-dimensional representations to reduce complexity and noise.\")\n",
        "\n",
        "# 5. Combining Processed Features for Model Training\n",
        "print(\"\\n5. Combining Processed Features for Model Training:\")\n",
        "print(\"The processed structured features (e.g., one-hot encoded variables) and the extracted features from unstructured data (e.g., vectorized text features, audio features) can be concatenated into a single feature vector for each patient. This combined feature vector can then be used as input for various machine learning models (e.g., logistic regression, support vector machines, neural networks) for breast cancer detection.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Data Collection:\n",
            "Structured Data: Collected from electronic health records (EHRs), patient intake forms, and potentially patient surveys. Methods include database queries and API integrations with EHR systems.\n",
            "Unstructured Data: Collected from medical imaging systems (Radiology Reports), laboratory information systems (Pathology Reports), transcription of doctor's notes, and the multilingual voice assistant nurse recordings.\n",
            "\n",
            "2. Cleaning Structured Data:\n",
            "- Handling Missing Values: Missing numerical data (e.g., age) can be imputed using mean, median, or regression imputation. Missing categorical data (e.g., family history) can be imputed using mode or by creating a 'missing' category. Alternatively, rows with a high percentage of missing values for critical features might be removed.\n",
            "- Identifying and Correcting Inconsistencies: Data validation rules can be applied to ensure data is within expected ranges (e.g., age between 0 and 120). Inconsistent categorical entries (e.g., different spellings of the same condition) can be standardized using mapping or lookup tables.\n",
            "- Addressing Outliers: Outliers in numerical data can be identified using methods like Z-scores or IQR and handled by capping, transformation, or removal, depending on the analysis's sensitivity to extreme values.\n",
            "\n",
            "3. Preprocessing Unstructured Data:\n",
            "Text Data (Doctor's Notes, Pathology Reports, Radiology Reports):\n",
            "-- Tokenization: Breaking down text into individual words or sub-word units.\n",
            "-- Lowercasing: Converting all text to lowercase for consistency.\n",
            "-- Removing Stop Words: Eliminating common words that do not carry significant meaning (e.g., 'the', 'a', 'is').\n",
            "-- Stemming or Lemmatization: Reducing words to their root form.\n",
            "-- Vectorization: Converting text into numerical representations using techniques like TF-IDF, Word2Vec, or BERT embeddings.\n",
            "Audio Data (Audio Recordings of Patient-Voice Assistant Interactions):\n",
            "-- Noise Reduction: Applying filters to minimize background noise.\n",
            "-- Silence Removal: Removing periods of silence.\n",
            "-- Feature Extraction: Extracting relevant features like Mel-Frequency Cepstral Coefficients (MFCCs), pitch, and energy.\n",
            "\n",
            "4. Feature Extraction and Engineering:\n",
            "Structured Data: Categorical features (e.g., Gender, Family History of Cancer) can be converted into numerical format using one-hot encoding.\n",
            "Unstructured Data: The numerical representations from text and audio preprocessing (e.g., TF-IDF vectors, embeddings, MFCCs) serve as features. Dimensionality reduction techniques like PCA or t-SNE might be applied to high-dimensional representations to reduce complexity and noise.\n",
            "\n",
            "5. Combining Processed Features for Model Training:\n",
            "The processed structured features (e.g., one-hot encoded variables) and the extracted features from unstructured data (e.g., vectorized text features, audio features) can be concatenated into a single feature vector for each patient. This combined feature vector can then be used as input for various machine learning models (e.g., logistic regression, support vector machines, neural networks) for breast cancer detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d967fd23"
      },
      "source": [
        "## Design the machine learning model\n",
        "\n",
        "### Subtask:\n",
        "Choose appropriate machine learning models for breast cancer detection based on the available data. This may involve using different models for different data types (e.g., image analysis for mammograms, NLP for text reports).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8a8219d"
      },
      "source": [
        "**Reasoning**:\n",
        "Discuss potential machine learning models for handling the combined structured and unstructured data and suggest specific model architectures for unstructured data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92a40296",
        "outputId": "c879db8d-007d-45ce-b3cf-629c43dd0d29"
      },
      "source": [
        "# 1. Models for Combined Structured and Unstructured Data\n",
        "print(\"1. Potential Machine Learning Models for Combined Data:\")\n",
        "print(\"Given the combination of structured (numerical/categorical) and unstructured (text, audio, potentially image) data, models capable of handling mixed data types or hierarchical processing are suitable.\")\n",
        "print(\"- **Ensemble Methods:** Models like Random Forests or Gradient Boosting Machines can handle both numerical and categorical features from structured data. Their predictions can be combined with outputs from models processing unstructured data.\")\n",
        "print(\"- **Hybrid Neural Networks:** Architectures that integrate different types of layers, such as dense layers for structured data and specialized layers (CNNs, RNNs/Transformers) for unstructured data. The outputs of these specialized layers can be concatenated with structured features before being fed into final classification layers.\")\n",
        "print(\"- **Multi-modal Learning Approaches:** Techniques specifically designed to process and fuse information from multiple data modalities. This could involve training separate models for each data type and then using another model to combine their predictions or learned representations.\")\n",
        "print(\"- **Support Vector Machines (SVMs):** While primarily designed for numerical data, SVMs can be used with kernels that handle different data types, or by concatenating features from different sources.\")\n",
        "\n",
        "# 2. Specific Model Architectures for Unstructured Data\n",
        "print(\"\\n2. Specific Model Architectures for Unstructured Data:\")\n",
        "print(\"Text Data (Doctor's Notes, Pathology Reports, Radiology Reports):\")\n",
        "print(\"- **Recurrent Neural Networks (RNNs) and LSTMs/GRUs:** Effective for sequential data like text, capturing dependencies and context.\")\n",
        "print(\"- **Transformer Networks (e.g., BERT, clinicalBERT):** State-of-the-art for many NLP tasks, capable of capturing complex relationships and context within text. Fine-tuning pre-trained models on medical text is often beneficial.\")\n",
        "print(\"- **Convolutional Neural Networks (CNNs):** Can also be used for text by treating sequences of word embeddings as an image, capturing local patterns (n-grams).\")\n",
        "print(\"Audio Data (Audio Recordings of Patient-Voice Assistant Interactions):\")\n",
        "print(\"- **Convolutional Neural Networks (CNNs):** Effective for analyzing spectral features of audio data (e.g., spectrograms).\")\n",
        "print(\"- **Recurrent Neural Networks (RNNs) or LSTMs/GRUs:** Can process sequential audio features (e.g., MFCCs) to capture temporal dynamics.\")\n",
        "print(\"- **Hybrid CNN-RNN Models:** Combining CNNs for local feature extraction and RNNs for temporal modeling.\")\n",
        "print(\"Image Data (if mammograms are included):\")\n",
        "print(\"- **Convolutional Neural Networks (CNNs):** The standard for image analysis, with architectures like ResNet, Inception, or U-Net (for segmentation) being highly effective for medical imaging.\")\n",
        "print(\"- **Transfer Learning:** Utilizing pre-trained CNNs on large image datasets (like ImageNet) and fine-tuning them on mammogram data can significantly improve performance, especially with limited medical image data.\")\n",
        "\n",
        "# 3. Combining Outputs from Different Models\n",
        "print(\"\\n3. Combining Outputs from Different Models:\")\n",
        "print(\"There are several ways to combine the outputs or learned representations from models handling different data types:\")\n",
        "print(\"- **Feature Concatenation:** As mentioned in preprocessing, the numerical features from structured data and the high-level features extracted by specialized models from unstructured data can be concatenated into a single vector and fed into a final classifier (e.g., a dense neural network, logistic regression, or SVM).\")\n",
        "print(\"- **Ensemble of Models:** Train separate models for each data type (e.g., a model for structured data, an NLP model for text, an audio model). The final prediction can be made by averaging, voting, or using another model (a meta-classifier) to combine the individual model predictions.\")\n",
        "print(\"- **End-to-End Multi-modal Learning:** Design a single, complex neural network architecture with separate branches for each data modality. These branches process their respective data types, and their outputs are merged at a later layer before the final prediction layer. This allows the model to learn how to best integrate information from different sources.\")\n",
        "print(\"- **Attention Mechanisms:** Incorporate attention mechanisms in hybrid or multi-modal networks to allow the model to selectively focus on the most relevant features or parts of the data from each modality when making a prediction.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Potential Machine Learning Models for Combined Data:\n",
            "Given the combination of structured (numerical/categorical) and unstructured (text, audio, potentially image) data, models capable of handling mixed data types or hierarchical processing are suitable.\n",
            "- **Ensemble Methods:** Models like Random Forests or Gradient Boosting Machines can handle both numerical and categorical features from structured data. Their predictions can be combined with outputs from models processing unstructured data.\n",
            "- **Hybrid Neural Networks:** Architectures that integrate different types of layers, such as dense layers for structured data and specialized layers (CNNs, RNNs/Transformers) for unstructured data. The outputs of these specialized layers can be concatenated with structured features before being fed into final classification layers.\n",
            "- **Multi-modal Learning Approaches:** Techniques specifically designed to process and fuse information from multiple data modalities. This could involve training separate models for each data type and then using another model to combine their predictions or learned representations.\n",
            "- **Support Vector Machines (SVMs):** While primarily designed for numerical data, SVMs can be used with kernels that handle different data types, or by concatenating features from different sources.\n",
            "\n",
            "2. Specific Model Architectures for Unstructured Data:\n",
            "Text Data (Doctor's Notes, Pathology Reports, Radiology Reports):\n",
            "- **Recurrent Neural Networks (RNNs) and LSTMs/GRUs:** Effective for sequential data like text, capturing dependencies and context.\n",
            "- **Transformer Networks (e.g., BERT, clinicalBERT):** State-of-the-art for many NLP tasks, capable of capturing complex relationships and context within text. Fine-tuning pre-trained models on medical text is often beneficial.\n",
            "- **Convolutional Neural Networks (CNNs):** Can also be used for text by treating sequences of word embeddings as an image, capturing local patterns (n-grams).\n",
            "Audio Data (Audio Recordings of Patient-Voice Assistant Interactions):\n",
            "- **Convolutional Neural Networks (CNNs):** Effective for analyzing spectral features of audio data (e.g., spectrograms).\n",
            "- **Recurrent Neural Networks (RNNs) or LSTMs/GRUs:** Can process sequential audio features (e.g., MFCCs) to capture temporal dynamics.\n",
            "- **Hybrid CNN-RNN Models:** Combining CNNs for local feature extraction and RNNs for temporal modeling.\n",
            "Image Data (if mammograms are included):\n",
            "- **Convolutional Neural Networks (CNNs):** The standard for image analysis, with architectures like ResNet, Inception, or U-Net (for segmentation) being highly effective for medical imaging.\n",
            "- **Transfer Learning:** Utilizing pre-trained CNNs on large image datasets (like ImageNet) and fine-tuning them on mammogram data can significantly improve performance, especially with limited medical image data.\n",
            "\n",
            "3. Combining Outputs from Different Models:\n",
            "There are several ways to combine the outputs or learned representations from models handling different data types:\n",
            "- **Feature Concatenation:** As mentioned in preprocessing, the numerical features from structured data and the high-level features extracted by specialized models from unstructured data can be concatenated into a single vector and fed into a final classifier (e.g., a dense neural network, logistic regression, or SVM).\n",
            "- **Ensemble of Models:** Train separate models for each data type (e.g., a model for structured data, an NLP model for text, an audio model). The final prediction can be made by averaging, voting, or using another model (a meta-classifier) to combine the individual model predictions.\n",
            "- **End-to-End Multi-modal Learning:** Design a single, complex neural network architecture with separate branches for each data modality. These branches process their respective data types, and their outputs are merged at a later layer before the final prediction layer. This allows the model to learn how to best integrate information from different sources.\n",
            "- **Attention Mechanisms:** Incorporate attention mechanisms in hybrid or multi-modal networks to allow the model to selectively focus on the most relevant features or parts of the data from each modality when making a prediction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ff3440"
      },
      "source": [
        "## Integrate voice assistant functionality\n",
        "\n",
        "### Subtask:\n",
        "Plan how the voice assistant will interact with the user, including speech-to-text for input, text-to-speech for output, and natural language processing to understand and respond to user queries in multiple languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbfbfc64"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the interaction flow, required components, NLP process, response generation, and integration for the multilingual voice assistant.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63a92862",
        "outputId": "c3a2a582-d760-4e4e-f761-d854cadac34a"
      },
      "source": [
        "# 1. Voice Assistant Interaction Flow\n",
        "print(\"1. Voice Assistant Interaction Flow:\")\n",
        "print(\"The interaction will typically follow these steps:\")\n",
        "print(\"- **Greeting and Initialization:** The assistant greets the user in their preferred language (if known) or asks for language preference.\")\n",
        "print(\"- **Listening for User Input:** The assistant activates its speech-to-text component to listen for the user's query or statement.\")\n",
        "print(\"- **Speech-to-Text Conversion:** The spoken input is converted into text.\")\n",
        "print(\"- **Language Detection (if needed):** If the language is not pre-determined, the system detects the language of the transcribed text.\")\n",
        "print(\"- **Natural Language Processing (NLP):** The text is processed to understand the user's intent, extract relevant information (e.g., symptoms, questions about risk factors, requests for information), and identify the language.\")\n",
        "print(\"- **Information Retrieval/Action:** Based on the NLP output, the system retrieves relevant information from the knowledge base or triggers an action (e.g., logging a symptom, accessing risk assessment data).\")\n",
        "print(\"- **Response Generation:** A response is formulated based on the retrieved information or action taken. This response is generated as text in the user's detected or preferred language.\")\n",
        "print(\"- **Text-to-Speech Conversion:** The text response is converted into spoken language.\")\n",
        "print(\"- **Speaking the Response:** The assistant speaks the response to the user.\")\n",
        "print(\"- **Continuing or Ending Interaction:** The assistant may ask if the user has further questions or if they are finished, looping back to the listening phase or ending the session.\")\n",
        "\n",
        "# 2. Components for Speech-to-Text (STT)\n",
        "print(\"\\n2. Components for Speech-to-Text (STT):\")\n",
        "print(\"To handle multilingual input, the STT component needs to be robust:\")\n",
        "print(\"- **Acoustic Model:** Trained on diverse speech data across multiple languages and accents to accurately convert audio signals into phonemes or sub-word units.\")\n",
        "print(\"- **Language Model:** Predicts sequences of words based on the language, helping to resolve ambiguities in the acoustic model's output. Separate language models for each supported language, or a single large multilingual model, can be used.\")\n",
        "print(\"- **Decoder:** Combines the outputs of the acoustic and language models to produce the most likely sequence of words (the transcribed text).\")\n",
        "print(\"- **Multilingual Support:** This can be achieved through training a single end-to-end multilingual model, or by having separate language-specific models and using a language identification step before STT.\")\n",
        "\n",
        "# 3. Natural Language Processing (NLP) Process\n",
        "print(\"\\n3. Natural Language Processing (NLP) Process:\")\n",
        "print(\"The NLP component is crucial for understanding the user's intent and extracting information:\")\n",
        "print(\"- **Language Identification:** Determine the language of the transcribed text if not already known.\")\n",
        "print(\"- **Tokenization:** Breaking down the text into words, punctuation, etc.\")\n",
        "print(\"- **Part-of-Speech Tagging:** Identifying the grammatical role of each word.\")\n",
        "print(\"- **Named Entity Recognition (NER):** Identifying and classifying entities like symptoms, medical conditions, body parts, and time references.\")\n",
        "print(\"- **Intent Recognition:** Determining the user's goal or purpose (e.g., 'report a symptom', 'ask about family history', 'get information about mammograms').\")\n",
        "print(\"- **Relationship Extraction:** Identifying how different entities in the text relate to each other.\")\n",
        "print(\"- **Multilingual NLP Models:** Using pre-trained multilingual models (like multilingual BERT) or training separate NLP pipelines for each supported language.\")\n",
        "print(\"- **Context Management:** Keeping track of the conversation history to understand follow-up questions and referential phrases.\")\n",
        "\n",
        "# 4. Text-to-Speech (TTS) for Response Generation\n",
        "print(\"\\n4. Text-to-Speech (TTS) for Response Generation:\")\n",
        "print(\"The TTS component converts the generated text response into natural-sounding speech:\")\n",
        "print(\"- **Text Normalization:** Converting numbers, abbreviations, and symbols into their spoken form.\")\n",
        "print(\"- **Grapheme-to-Phoneme Conversion:** Converting written words into their phonetic pronunciation.\")\n",
        "print(\"- **Prosody Prediction:** Determining the intonation, rhythm, and emphasis of the speech.\")\n",
        "print(\"- **Audio Synthesis:** Generating the audio waveform based on the phonetic and prosody information.\")\n",
        "print(\"- **Multilingual and Multi-speaker Capabilities:** The TTS system needs to support generating speech in all required languages and potentially with different voice options.\")\n",
        "\n",
        "# 5. Integration with the Breast Cancer Detection System\n",
        "print(\"\\n5. Integration with the Breast Cancer Detection System:\")\n",
        "print(\"The voice assistant acts as an interface between the user and the core system:\")\n",
        "print(\"- **Relaying User Information:** The extracted information from the NLP process (e.g., reported symptoms, risk factor details) is structured and sent to the appropriate modules of the detection system for storage, risk assessment, or analysis.\")\n",
        "print(\"- **Querying the System:** User questions or requests for information are processed by NLP, and relevant queries are sent to the system's knowledge base, data analysis modules, or model inference components.\")\n",
        "print(\"- **Presenting Results and Information:** The system sends results (e.g., risk assessment outcomes, information about breast cancer, explanations of concepts) back to the voice assistant as text. The assistant then uses TTS to present this information to the user in a clear and understandable manner.\")\n",
        "print(\"- **Handling Follow-up Questions:** The assistant maintains context to handle follow-up questions related to the information just provided or previous interactions.\")\n",
        "print(\"- **Error Handling and Clarification:** If the NLP component is unsure of the user's intent or needs more information, the voice assistant will use TTS to ask clarifying questions.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Voice Assistant Interaction Flow:\n",
            "The interaction will typically follow these steps:\n",
            "- **Greeting and Initialization:** The assistant greets the user in their preferred language (if known) or asks for language preference.\n",
            "- **Listening for User Input:** The assistant activates its speech-to-text component to listen for the user's query or statement.\n",
            "- **Speech-to-Text Conversion:** The spoken input is converted into text.\n",
            "- **Language Detection (if needed):** If the language is not pre-determined, the system detects the language of the transcribed text.\n",
            "- **Natural Language Processing (NLP):** The text is processed to understand the user's intent, extract relevant information (e.g., symptoms, questions about risk factors, requests for information), and identify the language.\n",
            "- **Information Retrieval/Action:** Based on the NLP output, the system retrieves relevant information from the knowledge base or triggers an action (e.g., logging a symptom, accessing risk assessment data).\n",
            "- **Response Generation:** A response is formulated based on the retrieved information or action taken. This response is generated as text in the user's detected or preferred language.\n",
            "- **Text-to-Speech Conversion:** The text response is converted into spoken language.\n",
            "- **Speaking the Response:** The assistant speaks the response to the user.\n",
            "- **Continuing or Ending Interaction:** The assistant may ask if the user has further questions or if they are finished, looping back to the listening phase or ending the session.\n",
            "\n",
            "2. Components for Speech-to-Text (STT):\n",
            "To handle multilingual input, the STT component needs to be robust:\n",
            "- **Acoustic Model:** Trained on diverse speech data across multiple languages and accents to accurately convert audio signals into phonemes or sub-word units.\n",
            "- **Language Model:** Predicts sequences of words based on the language, helping to resolve ambiguities in the acoustic model's output. Separate language models for each supported language, or a single large multilingual model, can be used.\n",
            "- **Decoder:** Combines the outputs of the acoustic and language models to produce the most likely sequence of words (the transcribed text).\n",
            "- **Multilingual Support:** This can be achieved through training a single end-to-end multilingual model, or by having separate language-specific models and using a language identification step before STT.\n",
            "\n",
            "3. Natural Language Processing (NLP) Process:\n",
            "The NLP component is crucial for understanding the user's intent and extracting information:\n",
            "- **Language Identification:** Determine the language of the transcribed text if not already known.\n",
            "- **Tokenization:** Breaking down the text into words, punctuation, etc.\n",
            "- **Part-of-Speech Tagging:** Identifying the grammatical role of each word.\n",
            "- **Named Entity Recognition (NER):** Identifying and classifying entities like symptoms, medical conditions, body parts, and time references.\n",
            "- **Intent Recognition:** Determining the user's goal or purpose (e.g., 'report a symptom', 'ask about family history', 'get information about mammograms').\n",
            "- **Relationship Extraction:** Identifying how different entities in the text relate to each other.\n",
            "- **Multilingual NLP Models:** Using pre-trained multilingual models (like multilingual BERT) or training separate NLP pipelines for each supported language.\n",
            "- **Context Management:** Keeping track of the conversation history to understand follow-up questions and referential phrases.\n",
            "\n",
            "4. Text-to-Speech (TTS) for Response Generation:\n",
            "The TTS component converts the generated text response into natural-sounding speech:\n",
            "- **Text Normalization:** Converting numbers, abbreviations, and symbols into their spoken form.\n",
            "- **Grapheme-to-Phoneme Conversion:** Converting written words into their phonetic pronunciation.\n",
            "- **Prosody Prediction:** Determining the intonation, rhythm, and emphasis of the speech.\n",
            "- **Audio Synthesis:** Generating the audio waveform based on the phonetic and prosody information.\n",
            "- **Multilingual and Multi-speaker Capabilities:** The TTS system needs to support generating speech in all required languages and potentially with different voice options.\n",
            "\n",
            "5. Integration with the Breast Cancer Detection System:\n",
            "The voice assistant acts as an interface between the user and the core system:\n",
            "- **Relaying User Information:** The extracted information from the NLP process (e.g., reported symptoms, risk factor details) is structured and sent to the appropriate modules of the detection system for storage, risk assessment, or analysis.\n",
            "- **Querying the System:** User questions or requests for information are processed by NLP, and relevant queries are sent to the system's knowledge base, data analysis modules, or model inference components.\n",
            "- **Presenting Results and Information:** The system sends results (e.g., risk assessment outcomes, information about breast cancer, explanations of concepts) back to the voice assistant as text. The assistant then uses TTS to present this information to the user in a clear and understandable manner.\n",
            "- **Handling Follow-up Questions:** The assistant maintains context to handle follow-up questions related to the information just provided or previous interactions.\n",
            "- **Error Handling and Clarification:** If the NLP component is unsure of the user's intent or needs more information, the voice assistant will use TTS to ask clarifying questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb521850"
      },
      "source": [
        "## Develop the system architecture\n",
        "\n",
        "### Subtask:\n",
        "Design the overall architecture of the system, including how the different components (data collection, processing, machine learning model, voice assistant) will interact with each other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1061690e"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the major components of the system and describe the flow of data and interactions between them, as requested by steps 1 and 2 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fa638be",
        "outputId": "ac332a59-d75d-4db4-c6a2-9c42c10a8e89"
      },
      "source": [
        "# 1. Outline the major components of the system\n",
        "print(\"Major Components of the Breast Cancer Detection System Architecture:\")\n",
        "print(\"\\n1. Data Layer:\")\n",
        "print(\"   - Structured Data Storage: Database (e.g., SQL, NoSQL) for storing structured patient information (age, gender, family history, etc.).\")\n",
        "print(\"   - Unstructured Data Storage: Data lake or distributed file system (e.g., S3, HDFS) for storing unstructured data (doctor's notes, radiology reports, audio recordings, images).\")\n",
        "print(\"   - Knowledge Base: Stores medical information, guidelines, and pre-defined responses for the voice assistant.\")\n",
        "\n",
        "print(\"\\n2. Data Processing Layer:\")\n",
        "print(\"   - Data Ingestion Module: Handles receiving data from various sources (EHRs, voice assistant, manual uploads).\")\n",
        "print(\"   - Data Cleaning and Validation Module: Performs tasks like handling missing values, standardizing formats, and correcting inconsistencies for structured data.\")\n",
        "print(\"   - Preprocessing Module: Handles text preprocessing (tokenization, stemming, vectorization), audio feature extraction (MFCCs, etc.), and image preprocessing.\")\n",
        "print(\"   - Feature Engineering Module: Creates new features from existing ones and combines features from different data types.\")\n",
        "\n",
        "print(\"\\n3. Machine Learning Layer:\")\n",
        "print(\"   - Model Repository: Stores trained machine learning models for different data types and combined data.\")\n",
        "print(\"   - Model Inference Module: Runs the trained models on new incoming data to generate predictions or insights (e.g., risk assessment score, identification of suspicious areas in reports).\")\n",
        "print(\"   - Model Training and Evaluation Module: Manages the process of training new models and evaluating their performance.\")\n",
        "\n",
        "print(\"\\n4. Voice Assistant Layer:\")\n",
        "print(\"   - Speech-to-Text (STT) Module: Converts user's spoken input into text (multilingual).\")\n",
        "print(\"   - Natural Language Processing (NLP) Module: Understands user intent, extracts information, and manages dialogue (multilingual).\")\n",
        "print(\"   - Text-to-Speech (TTS) Module: Converts system's text responses into spoken language (multilingual).\")\n",
        "print(\"   - Dialogue Management Module: Manages the conversation flow and context.\")\n",
        "\n",
        "print(\"\\n5. Application Layer:\")\n",
        "print(\"   - User Interface (UI) Module: Provides a visual interface for users (patients, healthcare providers) to interact with the system (optional, in addition to voice).\")\n",
        "print(\"   - API Gateway: Manages communication between the Application Layer, Voice Assistant Layer, and the backend services.\")\n",
        "print(\"   - User Session Management Module: Handles user authentication and maintains session state.\")\n",
        "print(\"   - Interaction Logic Module: Coordinates the flow between the voice assistant, backend processing, and presentation of information.\")\n",
        "\n",
        "# 2. Describe the flow of data and interactions between these components\n",
        "print(\"\\nData Flow and Interactions:\")\n",
        "print(\"\\n- **User Interaction via Voice Assistant:**\")\n",
        "print(\"  - User speaks to the Voice Assistant Layer.\")\n",
        "print(\"  - STT Module converts speech to text.\")\n",
        "print(\"  - NLP Module processes text to understand intent and extract information.\")\n",
        "print(\"  - Dialogue Management Module manages the conversation state.\")\n",
        "\n",
        "print(\"\\n- **Processing User Input and Querying the System:**\")\n",
        "print(\"  - Extracted information and intent are passed to the Application Layer (Interaction Logic Module).\")\n",
        "print(\"  - Application Layer determines necessary actions: logging symptoms, querying the Knowledge Base, or triggering data processing/ML inference.\")\n",
        "print(\"  - For data processing/ML inference, relevant data (structured, unstructured audio) is retrieved from the Data Layer.\")\n",
        "\n",
        "print(\"\\n- **Data Processing and ML Inference:**\")\n",
        "print(\"  - Raw data enters the Data Processing Layer (Ingestion Module).\")\n",
        "print(\"  - Data is cleaned, preprocessed, and features are engineered.\")\n",
        "print(\"  - Processed data is sent to the Machine Learning Layer (Model Inference Module).\")\n",
        "print(\"  - Trained models in the Model Repository generate predictions/insights based on the processed data.\")\n",
        "\n",
        "print(\"\\n- **Generating and Delivering Response:**\")\n",
        "print(\"  - ML results, information from the Knowledge Base, or system status are sent back to the Application Layer.\")\n",
        "print(\"  - Application Layer formulates a text response.\")\n",
        "print(\"  - Text response is sent to the Voice Assistant Layer (TTS Module).\")\n",
        "print(\"  - TTS Module converts text to speech.\")\n",
        "print(\"  - Voice Assistant speaks the response to the user.\")\n",
        "\n",
        "print(\"\\n- **Data Storage:**\")\n",
        "print(\"  - Collected structured and unstructured data is stored in the Data Layer.\")\n",
        "print(\"  - Processed data or model outputs might also be stored for analysis or auditing.\")\n",
        "\n",
        "print(\"\\n- **Healthcare Provider Interaction (via UI):**\")\n",
        "print(\"  - Healthcare providers interact with the system via the Application Layer (UI Module).\")\n",
        "print(\"  - UI communicates with backend services (Data Processing, ML Layer) via the API Gateway to access patient data, view results, or configure the system.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major Components of the Breast Cancer Detection System Architecture:\n",
            "\n",
            "1. Data Layer:\n",
            "   - Structured Data Storage: Database (e.g., SQL, NoSQL) for storing structured patient information (age, gender, family history, etc.).\n",
            "   - Unstructured Data Storage: Data lake or distributed file system (e.g., S3, HDFS) for storing unstructured data (doctor's notes, radiology reports, audio recordings, images).\n",
            "   - Knowledge Base: Stores medical information, guidelines, and pre-defined responses for the voice assistant.\n",
            "\n",
            "2. Data Processing Layer:\n",
            "   - Data Ingestion Module: Handles receiving data from various sources (EHRs, voice assistant, manual uploads).\n",
            "   - Data Cleaning and Validation Module: Performs tasks like handling missing values, standardizing formats, and correcting inconsistencies for structured data.\n",
            "   - Preprocessing Module: Handles text preprocessing (tokenization, stemming, vectorization), audio feature extraction (MFCCs, etc.), and image preprocessing.\n",
            "   - Feature Engineering Module: Creates new features from existing ones and combines features from different data types.\n",
            "\n",
            "3. Machine Learning Layer:\n",
            "   - Model Repository: Stores trained machine learning models for different data types and combined data.\n",
            "   - Model Inference Module: Runs the trained models on new incoming data to generate predictions or insights (e.g., risk assessment score, identification of suspicious areas in reports).\n",
            "   - Model Training and Evaluation Module: Manages the process of training new models and evaluating their performance.\n",
            "\n",
            "4. Voice Assistant Layer:\n",
            "   - Speech-to-Text (STT) Module: Converts user's spoken input into text (multilingual).\n",
            "   - Natural Language Processing (NLP) Module: Understands user intent, extracts information, and manages dialogue (multilingual).\n",
            "   - Text-to-Speech (TTS) Module: Converts system's text responses into spoken language (multilingual).\n",
            "   - Dialogue Management Module: Manages the conversation flow and context.\n",
            "\n",
            "5. Application Layer:\n",
            "   - User Interface (UI) Module: Provides a visual interface for users (patients, healthcare providers) to interact with the system (optional, in addition to voice).\n",
            "   - API Gateway: Manages communication between the Application Layer, Voice Assistant Layer, and the backend services.\n",
            "   - User Session Management Module: Handles user authentication and maintains session state.\n",
            "   - Interaction Logic Module: Coordinates the flow between the voice assistant, backend processing, and presentation of information.\n",
            "\n",
            "Data Flow and Interactions:\n",
            "\n",
            "- **User Interaction via Voice Assistant:**\n",
            "  - User speaks to the Voice Assistant Layer.\n",
            "  - STT Module converts speech to text.\n",
            "  - NLP Module processes text to understand intent and extract information.\n",
            "  - Dialogue Management Module manages the conversation state.\n",
            "\n",
            "- **Processing User Input and Querying the System:**\n",
            "  - Extracted information and intent are passed to the Application Layer (Interaction Logic Module).\n",
            "  - Application Layer determines necessary actions: logging symptoms, querying the Knowledge Base, or triggering data processing/ML inference.\n",
            "  - For data processing/ML inference, relevant data (structured, unstructured audio) is retrieved from the Data Layer.\n",
            "\n",
            "- **Data Processing and ML Inference:**\n",
            "  - Raw data enters the Data Processing Layer (Ingestion Module).\n",
            "  - Data is cleaned, preprocessed, and features are engineered.\n",
            "  - Processed data is sent to the Machine Learning Layer (Model Inference Module).\n",
            "  - Trained models in the Model Repository generate predictions/insights based on the processed data.\n",
            "\n",
            "- **Generating and Delivering Response:**\n",
            "  - ML results, information from the Knowledge Base, or system status are sent back to the Application Layer.\n",
            "  - Application Layer formulates a text response.\n",
            "  - Text response is sent to the Voice Assistant Layer (TTS Module).\n",
            "  - TTS Module converts text to speech.\n",
            "  - Voice Assistant speaks the response to the user.\n",
            "\n",
            "- **Data Storage:**\n",
            "  - Collected structured and unstructured data is stored in the Data Layer.\n",
            "  - Processed data or model outputs might also be stored for analysis or auditing.\n",
            "\n",
            "- **Healthcare Provider Interaction (via UI):**\n",
            "  - Healthcare providers interact with the system via the Application Layer (UI Module).\n",
            "  - UI communicates with backend services (Data Processing, ML Layer) via the API Gateway to access patient data, view results, or configure the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126878ae"
      },
      "source": [
        "**Reasoning**:\n",
        "Explain how the multilingual voice assistant integrates with the rest of the system, how different machine learning models are incorporated and combined, and the role of the Application Layer, as requested by steps 3, 4, and 5 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77a0fc42",
        "outputId": "af255319-fa09-4ed5-c6a0-9c015ffb7b8f"
      },
      "source": [
        "# 3. Explain how the multilingual voice assistant layer integrates\n",
        "print(\"\\nIntegration of Multilingual Voice Assistant Layer:\")\n",
        "print(\"The Voice Assistant Layer serves as the primary user interface for voice interactions.\")\n",
        "print(\"- **Input:** It receives spoken input from the user. The STT Module, trained on multiple languages, transcribes this speech into text.\")\n",
        "print(\"- **Understanding:** The NLP Module, also designed for multilingual processing (either with language-specific models or a single multilingual model), analyzes the transcribed text to understand the user's intent (e.g., reporting a symptom, asking a question) and extracts key information (e.g., specific symptoms, duration, family history details). Language detection is a key initial step if the language isn't predetermined.\")\n",
        "print(\"- **System Interaction:** The NLP output, including the user's intent and extracted information, is passed to the Application Layer. The Application Layer acts as an orchestrator, directing the request to the appropriate backend components.\")\n",
        "print(\"  - If the user is reporting data (e.g., new symptoms), the Application Layer sends this structured information to the Data Processing Layer for validation and then to the Data Layer for storage.\")\n",
        "print(\"  - If the user is asking a question or requesting information (e.g., 'What are my risk factors?', 'Explain this pathology report'), the Application Layer queries the Knowledge Base or triggers a query to the Machine Learning Layer (for risk assessment or report analysis).\")\n",
        "print(\"- **Output:** The results from the Knowledge Base or Machine Learning Layer, or confirmation of data logging, are formatted into a text response by the Application Layer. This text response is sent back to the Voice Assistant Layer.\")\n",
        "print(\"- **Speaking:** The TTS Module, capable of generating speech in the detected or preferred language, converts the text response into natural-sounding audio, which is then played back to the user.\")\n",
        "print(\"- **Dialogue Management:** The Dialogue Management Module within the Voice Assistant Layer maintains the conversation context, allowing for follow-up questions and a more natural interaction flow.\")\n",
        "\n",
        "# 4. Consider how different machine learning models are incorporated and combined\n",
        "print(\"\\nIncorporation and Combination of Different Machine Learning Models:\")\n",
        "print(\"The Machine Learning Layer is designed to handle various data types and combine their insights.\")\n",
        "print(\"- **Specialized Models:** Separate models can be trained for different unstructured data types:\")\n",
        "print(\"  - NLP Models (e.g., Transformers) for analyzing text reports (doctor's notes, pathology, radiology). These models can identify key medical entities, relationships, and potentially classify report findings.\")\n",
        "print(\"  - Audio Analysis Models (e.g., CNNs, RNNs) for processing voice recordings from the assistant, potentially analyzing sentiment or identifying specific vocal cues (though the primary use here is likely STT).\")\n",
        "print(\"  - Image Analysis Models (e.g., CNNs) if mammograms or other medical images are included in the data pipeline. These models can detect suspicious regions or classify images.\")\n",
        "print(\"- **Structured Data Models:** Traditional ML models (e.g., Logistic Regression, Gradient Boosting) or simple neural networks can be used to process structured patient data.\")\n",
        "print(\"- **Combining Insights:** The outputs or learned features from these specialized models are combined within the Machine Learning Layer or the Data Processing Layer:\")\n",
        "print(\"  - **Feature Fusion:** Features extracted from unstructured data (e.g., embeddings from NLP models, features from image models) are concatenated with processed structured data features to create a unified feature vector.\")\n",
        "print(\"  - **Model Ensembling:** Predictions from individual models (e.g., a risk score from structured data, a finding classification from a radiology report NLP model) can be combined using a meta-classifier or weighted averaging to produce a final comprehensive assessment.\")\n",
        "print(\"  - **Multi-modal Networks:** An end-to-end deep learning model with separate input branches for different data types can be used, where the learned representations are merged within the network before the final output layer. This allows the model to learn optimal ways to combine information.\")\n",
        "print(\"- **Model Repository:** The Machine Learning Layer stores these various models, allowing the Model Inference Module to select and run the appropriate model(s) based on the input data.\")\n",
        "\n",
        "# 5. Briefly describe the role of the Application Layer\n",
        "print(\"\\nRole of the Application Layer:\")\n",
        "print(\"The Application Layer serves as the central control and coordination hub of the system.\")\n",
        "print(\"- **User Interface Management:** It handles the logic for any visual UI, presenting information from the backend to the user and receiving user input (though the primary focus here is voice).\")\n",
        "print(\"- **Voice Assistant Coordination:** It acts as the intermediary between the Voice Assistant Layer and the backend services (Data Layer, Data Processing Layer, Machine Learning Layer, Knowledge Base). It receives intents and data from the voice assistant, directs requests to the appropriate modules, and formats responses to be sent back to the voice assistant for TTS.\")\n",
        "print(\"- **User Session Management:** It manages user authentication, authorization, and maintains the state of user sessions, ensuring continuity in interactions and data access.\")\n",
        "print(\"- **Workflow Orchestration:** It contains the core interaction logic, defining how different user requests (via voice or UI) are processed, which data processing steps are needed, which ML models to invoke, and how the results are presented.\")\n",
        "print(\"- **API Gateway:** It exposes APIs for the Voice Assistant Layer and potentially external systems to interact with the backend, providing a standardized and secure interface.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Integration of Multilingual Voice Assistant Layer:\n",
            "The Voice Assistant Layer serves as the primary user interface for voice interactions.\n",
            "- **Input:** It receives spoken input from the user. The STT Module, trained on multiple languages, transcribes this speech into text.\n",
            "- **Understanding:** The NLP Module, also designed for multilingual processing (either with language-specific models or a single multilingual model), analyzes the transcribed text to understand the user's intent (e.g., reporting a symptom, asking a question) and extracts key information (e.g., specific symptoms, duration, family history details). Language detection is a key initial step if the language isn't predetermined.\n",
            "- **System Interaction:** The NLP output, including the user's intent and extracted information, is passed to the Application Layer. The Application Layer acts as an orchestrator, directing the request to the appropriate backend components.\n",
            "  - If the user is reporting data (e.g., new symptoms), the Application Layer sends this structured information to the Data Processing Layer for validation and then to the Data Layer for storage.\n",
            "  - If the user is asking a question or requesting information (e.g., 'What are my risk factors?', 'Explain this pathology report'), the Application Layer queries the Knowledge Base or triggers a query to the Machine Learning Layer (for risk assessment or report analysis).\n",
            "- **Output:** The results from the Knowledge Base or Machine Learning Layer, or confirmation of data logging, are formatted into a text response by the Application Layer. This text response is sent back to the Voice Assistant Layer.\n",
            "- **Speaking:** The TTS Module, capable of generating speech in the detected or preferred language, converts the text response into natural-sounding audio, which is then played back to the user.\n",
            "- **Dialogue Management:** The Dialogue Management Module within the Voice Assistant Layer maintains the conversation context, allowing for follow-up questions and a more natural interaction flow.\n",
            "\n",
            "Incorporation and Combination of Different Machine Learning Models:\n",
            "The Machine Learning Layer is designed to handle various data types and combine their insights.\n",
            "- **Specialized Models:** Separate models can be trained for different unstructured data types:\n",
            "  - NLP Models (e.g., Transformers) for analyzing text reports (doctor's notes, pathology, radiology). These models can identify key medical entities, relationships, and potentially classify report findings.\n",
            "  - Audio Analysis Models (e.g., CNNs, RNNs) for processing voice recordings from the assistant, potentially analyzing sentiment or identifying specific vocal cues (though the primary use here is likely STT).\n",
            "  - Image Analysis Models (e.g., CNNs) if mammograms or other medical images are included in the data pipeline. These models can detect suspicious regions or classify images.\n",
            "- **Structured Data Models:** Traditional ML models (e.g., Logistic Regression, Gradient Boosting) or simple neural networks can be used to process structured patient data.\n",
            "- **Combining Insights:** The outputs or learned features from these specialized models are combined within the Machine Learning Layer or the Data Processing Layer:\n",
            "  - **Feature Fusion:** Features extracted from unstructured data (e.g., embeddings from NLP models, features from image models) are concatenated with processed structured data features to create a unified feature vector.\n",
            "  - **Model Ensembling:** Predictions from individual models (e.g., a risk score from structured data, a finding classification from a radiology report NLP model) can be combined using a meta-classifier or weighted averaging to produce a final comprehensive assessment.\n",
            "  - **Multi-modal Networks:** An end-to-end deep learning model with separate input branches for different data types can be used, where the learned representations are merged within the network before the final output layer. This allows the model to learn optimal ways to combine information.\n",
            "- **Model Repository:** The Machine Learning Layer stores these various models, allowing the Model Inference Module to select and run the appropriate model(s) based on the input data.\n",
            "\n",
            "Role of the Application Layer:\n",
            "The Application Layer serves as the central control and coordination hub of the system.\n",
            "- **User Interface Management:** It handles the logic for any visual UI, presenting information from the backend to the user and receiving user input (though the primary focus here is voice).\n",
            "- **Voice Assistant Coordination:** It acts as the intermediary between the Voice Assistant Layer and the backend services (Data Layer, Data Processing Layer, Machine Learning Layer, Knowledge Base). It receives intents and data from the voice assistant, directs requests to the appropriate modules, and formats responses to be sent back to the voice assistant for TTS.\n",
            "- **User Session Management:** It manages user authentication, authorization, and maintains the state of user sessions, ensuring continuity in interactions and data access.\n",
            "- **Workflow Orchestration:** It contains the core interaction logic, defining how different user requests (via voice or UI) are processed, which data processing steps are needed, which ML models to invoke, and how the results are presented.\n",
            "- **API Gateway:** It exposes APIs for the Voice Assistant Layer and potentially external systems to interact with the backend, providing a standardized and secure interface.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74e97275"
      },
      "source": [
        "## Train and evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Outline the process for training and evaluating the machine learning model using the collected data, including selecting appropriate metrics and validation techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9443d3d"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the steps for preparing the data for model training, including splitting the data. Then explain the training process for different data modalities and discuss evaluation metrics and validation techniques. Finally, outline how models will be compared and selected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f40be7de",
        "outputId": "8af1f87e-792c-40de-d29a-9f376d80b46d"
      },
      "source": [
        "# 1. Data Preparation for Model Training\n",
        "print(\"1. Data Preparation for Model Training:\")\n",
        "print(\"- **Consolidation:** Combine processed features from all data modalities (structured data, vectorized text features, audio features, image features if applicable) into a single, unified dataset for each patient.\")\n",
        "print(\"- **Labeling:** Ensure the dataset includes the target variable, which is the breast cancer diagnosis (e.g., binary classification: 'Positive'/'Negative' or multi-class if different cancer types are considered). This requires accurate ground truth labels, typically from pathology reports confirmed by medical professionals.\")\n",
        "print(\"- **Handling Class Imbalance:** Breast cancer datasets are often imbalanced (fewer positive cases than negative). Techniques like oversampling the minority class (e.g., SMOTE), undersampling the majority class, or using class weights during training will be considered.\")\n",
        "print(\"- **Splitting the Data:** Divide the consolidated and labeled dataset into three sets:\")\n",
        "print(\"  - **Training Set:** Used to train the machine learning models (typically 70-80% of the data).\")\n",
        "print(\"  - **Validation Set:** Used to tune model hyperparameters and evaluate model performance during the training phase to prevent overfitting (typically 10-15% of the data).\")\n",
        "print(\"  - **Testing Set:** Held out entirely until the final model evaluation to provide an unbiased estimate of the model's performance on unseen data (typically 10-15% of the data). The split should be done carefully, potentially using stratified sampling to maintain the original class distribution in each set.\")\n",
        "\n",
        "# 2. Model Training Process\n",
        "print(\"\\n2. Model Training Process:\")\n",
        "print(\"The training process will vary depending on the chosen model architecture and data modalities:\")\n",
        "print(\"- **Training on Combined Data:** For models that process the unified feature vector (e.g., ensemble methods, hybrid neural networks), the model will be trained end-to-end on the training set, minimizing a chosen loss function (e.g., binary cross-entropy for classification).\")\n",
        "print(\"- **Training on Different Modalities (if using separate models):** If separate models are used for different data types (e.g., an NLP model for text, a CNN for images, a traditional model for structured data), each model will be trained independently on the relevant portion of the training data.\")\n",
        "print(\"- **Transfer Learning:** For modalities like text and images, leveraging pre-trained models (e.g., BERT for text, ResNet for images) fine-tuned on medical data can significantly improve performance, especially with limited training data.\")\n",
        "print(\"- **Hyperparameter Tuning:** The validation set will be used to tune hyperparameters (e.g., learning rate, number of layers, regularization strength) for all models to optimize performance.\")\n",
        "print(\"- **Addressing Overfitting:** Techniques like regularization (L1, L2), dropout (in neural networks), early stopping based on validation performance, and using sufficient training data will be employed.\")\n",
        "\n",
        "# 3. Evaluation Metrics\n",
        "print(\"\\n3. Appropriate Evaluation Metrics:\")\n",
        "print(\"For a breast cancer detection system, which is a classification task, several metrics are crucial, considering the potential for class imbalance and the high stakes of misclassification:\")\n",
        "print(\"- **Accuracy:** Overall proportion of correctly classified instances (both positive and negative). While intuitive, it can be misleading with imbalanced data.\")\n",
        "print(\"- **Precision (Positive Predictive Value):** Of all instances predicted as positive, what proportion were actually positive? High precision is important to minimize false positives, reducing unnecessary follow-up procedures.\")\n",
        "print(\"- **Recall (Sensitivity):** Of all actual positive instances, what proportion were correctly identified? High recall is critical to minimize false negatives, ensuring that actual cancer cases are detected.\")\n",
        "print(\"- **F1-score:** The harmonic mean of precision and recall, providing a single metric that balances both. Useful when there is an uneven class distribution.\")\n",
        "print(\"- **Specificity:** Of all actual negative instances, what proportion were correctly identified? Important to minimize false positives.\")\n",
        "print(\"- **AUC (Area Under the Receiver Operating Characteristic Curve):** Measures the model's ability to distinguish between positive and negative classes across various classification thresholds. A higher AUC indicates better discriminative power.\")\n",
        "print(\"- **Precision-Recall Curve and AUC-PR:** Particularly informative for imbalanced datasets, focusing on the performance on the positive class.\")\n",
        "print(\"The choice and weighting of these metrics will depend on the specific clinical requirements and the relative costs of false positives and false negatives.\")\n",
        "\n",
        "# 4. Validation Techniques\n",
        "print(\"\\n4. Validation Techniques:\")\n",
        "print(\"Validation techniques are essential to assess model performance reliably and prevent overfitting:\")\n",
        "print(\"- **Hold-out Validation:** Using the separate validation set (as described in Data Splitting) to evaluate the model during training and for hyperparameter tuning. This is a basic but effective method.\")\n",
        "print(\"- **Cross-Validation (k-Fold Cross-Validation):** The training data is split into k smaller subsets (folds). The model is trained k times, each time on k-1 folds and validated on the remaining fold. The results are averaged over all k folds. This provides a more robust estimate of model performance and better utilizes the available data, especially for smaller datasets.\")\n",
        "print(\"- **Stratified k-Fold Cross-Validation:** A variation of k-fold cross-validation where each fold contains approximately the same percentage of samples of each target class as the complete set. This is crucial for maintaining class distribution in each fold, especially with imbalanced datasets.\")\n",
        "print(\"- **Nested Cross-Validation:** Used for both hyperparameter tuning and model evaluation. An outer loop performs k-fold cross-validation for evaluation, while an inner loop performs cross-validation on the training folds of the outer loop for hyperparameter tuning. This provides a less biased estimate of the model's performance with tuned hyperparameters.\")\n",
        "\n",
        "# 5. Comparing and Selecting Models\n",
        "print(\"\\n5. Comparing and Selecting Models:\")\n",
        "print(\"The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\")\n",
        "print(\"- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\")\n",
        "print(\"- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\")\n",
        "print(\"- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\")\n",
        "print(\"- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\")\n",
        "print(\"- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Data Preparation for Model Training:\n",
            "- **Consolidation:** Combine processed features from all data modalities (structured data, vectorized text features, audio features, image features if applicable) into a single, unified dataset for each patient.\n",
            "- **Labeling:** Ensure the dataset includes the target variable, which is the breast cancer diagnosis (e.g., binary classification: 'Positive'/'Negative' or multi-class if different cancer types are considered). This requires accurate ground truth labels, typically from pathology reports confirmed by medical professionals.\n",
            "- **Handling Class Imbalance:** Breast cancer datasets are often imbalanced (fewer positive cases than negative). Techniques like oversampling the minority class (e.g., SMOTE), undersampling the majority class, or using class weights during training will be considered.\n",
            "- **Splitting the Data:** Divide the consolidated and labeled dataset into three sets:\n",
            "  - **Training Set:** Used to train the machine learning models (typically 70-80% of the data).\n",
            "  - **Validation Set:** Used to tune model hyperparameters and evaluate model performance during the training phase to prevent overfitting (typically 10-15% of the data).\n",
            "  - **Testing Set:** Held out entirely until the final model evaluation to provide an unbiased estimate of the model's performance on unseen data (typically 10-15% of the data). The split should be done carefully, potentially using stratified sampling to maintain the original class distribution in each set.\n",
            "\n",
            "2. Model Training Process:\n",
            "The training process will vary depending on the chosen model architecture and data modalities:\n",
            "- **Training on Combined Data:** For models that process the unified feature vector (e.g., ensemble methods, hybrid neural networks), the model will be trained end-to-end on the training set, minimizing a chosen loss function (e.g., binary cross-entropy for classification).\n",
            "- **Training on Different Modalities (if using separate models):** If separate models are used for different data types (e.g., an NLP model for text, a CNN for images, a traditional model for structured data), each model will be trained independently on the relevant portion of the training data.\n",
            "- **Transfer Learning:** For modalities like text and images, leveraging pre-trained models (e.g., BERT for text, ResNet for images) fine-tuned on medical data can significantly improve performance, especially with limited training data.\n",
            "- **Hyperparameter Tuning:** The validation set will be used to tune hyperparameters (e.g., learning rate, number of layers, regularization strength) for all models to optimize performance.\n",
            "- **Addressing Overfitting:** Techniques like regularization (L1, L2), dropout (in neural networks), early stopping based on validation performance, and using sufficient training data will be employed.\n",
            "\n",
            "3. Appropriate Evaluation Metrics:\n",
            "For a breast cancer detection system, which is a classification task, several metrics are crucial, considering the potential for class imbalance and the high stakes of misclassification:\n",
            "- **Accuracy:** Overall proportion of correctly classified instances (both positive and negative). While intuitive, it can be misleading with imbalanced data.\n",
            "- **Precision (Positive Predictive Value):** Of all instances predicted as positive, what proportion were actually positive? High precision is important to minimize false positives, reducing unnecessary follow-up procedures.\n",
            "- **Recall (Sensitivity):** Of all actual positive instances, what proportion were correctly identified? High recall is critical to minimize false negatives, ensuring that actual cancer cases are detected.\n",
            "- **F1-score:** The harmonic mean of precision and recall, providing a single metric that balances both. Useful when there is an uneven class distribution.\n",
            "- **Specificity:** Of all actual negative instances, what proportion were correctly identified? Important to minimize false positives.\n",
            "- **AUC (Area Under the Receiver Operating Characteristic Curve):** Measures the model's ability to distinguish between positive and negative classes across various classification thresholds. A higher AUC indicates better discriminative power.\n",
            "- **Precision-Recall Curve and AUC-PR:** Particularly informative for imbalanced datasets, focusing on the performance on the positive class.\n",
            "The choice and weighting of these metrics will depend on the specific clinical requirements and the relative costs of false positives and false negatives.\n",
            "\n",
            "4. Validation Techniques:\n",
            "Validation techniques are essential to assess model performance reliably and prevent overfitting:\n",
            "- **Hold-out Validation:** Using the separate validation set (as described in Data Splitting) to evaluate the model during training and for hyperparameter tuning. This is a basic but effective method.\n",
            "- **Cross-Validation (k-Fold Cross-Validation):** The training data is split into k smaller subsets (folds). The model is trained k times, each time on k-1 folds and validated on the remaining fold. The results are averaged over all k folds. This provides a more robust estimate of model performance and better utilizes the available data, especially for smaller datasets.\n",
            "- **Stratified k-Fold Cross-Validation:** A variation of k-fold cross-validation where each fold contains approximately the same percentage of samples of each target class as the complete set. This is crucial for maintaining class distribution in each fold, especially with imbalanced datasets.\n",
            "- **Nested Cross-Validation:** Used for both hyperparameter tuning and model evaluation. An outer loop performs k-fold cross-validation for evaluation, while an inner loop performs cross-validation on the training folds of the outer loop for hyperparameter tuning. This provides a less biased estimate of the model's performance with tuned hyperparameters.\n",
            "\n",
            "5. Comparing and Selecting Models:\n",
            "The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\n",
            "- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\n",
            "- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\n",
            "- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\n",
            "- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\n",
            "- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bca7eddd"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output was truncated. Regenerate the complete output for evaluating the machine learning model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62f027c6",
        "outputId": "f9289632-18be-4c20-a1ca-42d327f1beca"
      },
      "source": [
        "# 3. Appropriate Evaluation Metrics\n",
        "print(\"\\n3. Appropriate Evaluation Metrics:\")\n",
        "print(\"For a breast cancer detection system, which is a classification task, several metrics are crucial, considering the potential for class imbalance and the high stakes of misclassification:\")\n",
        "print(\"- **Accuracy:** Overall proportion of correctly classified instances (both positive and negative). While intuitive, it can be misleading with imbalanced data.\")\n",
        "print(\"- **Precision (Positive Predictive Value):** Of all instances predicted as positive, what proportion were actually positive? High precision is important to minimize false positives, reducing unnecessary follow-up procedures.\")\n",
        "print(\"- **Recall (Sensitivity):** Of all actual positive instances, what proportion were correctly identified? High recall is critical to minimize false negatives, ensuring that actual cancer cases are detected.\")\n",
        "print(\"- **F1-score:** The harmonic mean of precision and recall, providing a single metric that balances both. Useful when there is an uneven class distribution.\")\n",
        "print(\"- **Specificity:** Of all actual negative instances, what proportion were correctly identified? Important to minimize false positives.\")\n",
        "print(\"- **AUC (Area Under the Receiver Operating Characteristic Curve):** Measures the model's ability to distinguish between positive and negative classes across various classification thresholds. A higher AUC indicates better discriminative power.\")\n",
        "print(\"- **Precision-Recall Curve and AUC-PR:** Particularly informative for imbalanced datasets, focusing on the performance on the positive class.\")\n",
        "print(\"The choice and weighting of these metrics will depend on the specific clinical requirements and the relative costs of false positives and false negatives.\")\n",
        "\n",
        "# 4. Validation Techniques\n",
        "print(\"\\n4. Validation Techniques:\")\n",
        "print(\"Validation techniques are essential to assess model performance reliably and prevent overfitting:\")\n",
        "print(\"- **Hold-out Validation:** Using the separate validation set (as described in Data Splitting) to evaluate the model during training and for hyperparameter tuning. This is a basic but effective method.\")\n",
        "print(\"- **Cross-Validation (k-Fold Cross-Validation):** The training data is split into k smaller subsets (folds). The model is trained k times, each time on k-1 folds and validated on the remaining fold. The results are averaged over all k folds. This provides a more robust estimate of model performance and better utilizes the available data, especially for smaller datasets.\")\n",
        "print(\"- **Stratified k-Fold Cross-Validation:** A variation of k-fold cross-validation where each fold contains approximately the same percentage of samples of each target class as the complete set. This is crucial for maintaining class distribution in each fold, especially with imbalanced datasets.\")\n",
        "print(\"- **Nested Cross-Validation:** Used for both hyperparameter tuning and model evaluation. An outer loop performs k-fold cross-validation for evaluation, while an inner loop performs cross-validation on the training folds of the outer loop for hyperparameter tuning. This provides a less biased estimate of the model's performance with tuned hyperparameters.\")\n",
        "\n",
        "# 5. Comparing and Selecting Models\n",
        "print(\"\\n5. Comparing and Selecting Models:\")\n",
        "print(\"The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\")\n",
        "print(\"- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\")\n",
        "print(\"- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\")\n",
        "print(\"- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\")\n",
        "print(\"- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\")\n",
        "print(\"- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Appropriate Evaluation Metrics:\n",
            "For a breast cancer detection system, which is a classification task, several metrics are crucial, considering the potential for class imbalance and the high stakes of misclassification:\n",
            "- **Accuracy:** Overall proportion of correctly classified instances (both positive and negative). While intuitive, it can be misleading with imbalanced data.\n",
            "- **Precision (Positive Predictive Value):** Of all instances predicted as positive, what proportion were actually positive? High precision is important to minimize false positives, reducing unnecessary follow-up procedures.\n",
            "- **Recall (Sensitivity):** Of all actual positive instances, what proportion were correctly identified? High recall is critical to minimize false negatives, ensuring that actual cancer cases are detected.\n",
            "- **F1-score:** The harmonic mean of precision and recall, providing a single metric that balances both. Useful when there is an uneven class distribution.\n",
            "- **Specificity:** Of all actual negative instances, what proportion were correctly identified? Important to minimize false positives.\n",
            "- **AUC (Area Under the Receiver Operating Characteristic Curve):** Measures the model's ability to distinguish between positive and negative classes across various classification thresholds. A higher AUC indicates better discriminative power.\n",
            "- **Precision-Recall Curve and AUC-PR:** Particularly informative for imbalanced datasets, focusing on the performance on the positive class.\n",
            "The choice and weighting of these metrics will depend on the specific clinical requirements and the relative costs of false positives and false negatives.\n",
            "\n",
            "4. Validation Techniques:\n",
            "Validation techniques are essential to assess model performance reliably and prevent overfitting:\n",
            "- **Hold-out Validation:** Using the separate validation set (as described in Data Splitting) to evaluate the model during training and for hyperparameter tuning. This is a basic but effective method.\n",
            "- **Cross-Validation (k-Fold Cross-Validation):** The training data is split into k smaller subsets (folds). The model is trained k times, each time on k-1 folds and validated on the remaining fold. The results are averaged over all k folds. This provides a more robust estimate of model performance and better utilizes the available data, especially for smaller datasets.\n",
            "- **Stratified k-Fold Cross-Validation:** A variation of k-fold cross-validation where each fold contains approximately the same percentage of samples of each target class as the complete set. This is crucial for maintaining class distribution in each fold, especially with imbalanced datasets.\n",
            "- **Nested Cross-Validation:** Used for both hyperparameter tuning and model evaluation. An outer loop performs k-fold cross-validation for evaluation, while an inner loop performs cross-validation on the training folds of the outer loop for hyperparameter tuning. This provides a less biased estimate of the model's performance with tuned hyperparameters.\n",
            "\n",
            "5. Comparing and Selecting Models:\n",
            "The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\n",
            "- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\n",
            "- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\n",
            "- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\n",
            "- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\n",
            "- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468ca9f2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output was truncated again. Regenerate the complete output for comparing and selecting models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f47c48a",
        "outputId": "e94d63e7-3c2f-47f5-afe7-c4d8281bfe05"
      },
      "source": [
        "# 5. Comparing and Selecting Models\n",
        "print(\"\\n5. Comparing and Selecting Models:\")\n",
        "print(\"The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\")\n",
        "print(\"- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\")\n",
        "print(\"- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\")\n",
        "print(\"- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\")\n",
        "print(\"- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\")\n",
        "print(\"- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Comparing and Selecting Models:\n",
            "The performance of different models (trained on different modalities or combined data) will be compared using the chosen evaluation metrics on the independent testing set:\n",
            "- **Quantitative Comparison:** Calculate and compare the values of key metrics (e.g., Recall, Precision, F1-score, AUC) on the test set for each trained model.\n",
            "- **Considering Clinical Impact:** Beyond just numerical metrics, evaluate which model's performance aligns best with clinical requirements (e.g., is minimizing false negatives paramount, even if it means a slight increase in false positives?).\n",
            "- **Analyzing Performance on Different Subgroups:** If possible, analyze model performance on different patient subgroups (e.g., by age, ethnicity) to ensure fairness and identify potential biases.\n",
            "- **Model Complexity and Interpretability:** Consider the complexity of the models. Simpler, more interpretable models might be preferred if their performance is comparable to complex black-box models, especially for clinical acceptance.\n",
            "- **Selecting the Best Model(s):** Based on the quantitative evaluation, clinical considerations, and potentially model interpretability, select the model or a combination of models that demonstrate the most promising and reliable performance on the breast cancer detection task. It might be that different models perform best for different aspects of the detection (e.g., one model for initial screening, another for analyzing specific report types).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2ba194"
      },
      "source": [
        "## Integrate and test the system\n",
        "\n",
        "### Subtask:\n",
        "Plan how the machine learning model and voice assistant will be integrated into a single system and how the system will be tested to ensure its accuracy and usability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69b5a6c6"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps for integrating the machine learning model and voice assistant, and describe the testing plan for the system.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e85c2fd2",
        "outputId": "9edfaf0c-15dd-4097-a6a1-a335a07b6c5e"
      },
      "source": [
        "# 1. Integration of ML Model and Voice Assistant\n",
        "print(\"1. Integration of ML Model and Voice Assistant:\")\n",
        "print(\"- The voice assistant's NLP module processes user input (transcribed text) to extract relevant medical information (symptoms, history, questions) and determine user intent.\")\n",
        "print(\"- This structured information is passed to the Application Layer.\")\n",
        "print(\"- The Application Layer, based on the user's intent, interacts with the Data Processing Layer to prepare the relevant patient data (structured + processed unstructured data).\")\n",
        "print(\"- The prepared data is then sent to the Machine Learning Layer's Model Inference Module.\")\n",
        "print(\"- The Model Inference Module loads and runs the appropriate trained ML model(s) on the data.\")\n",
        "print(\"- The results from the ML model(s) (e.g., risk assessment score, analysis of reported symptoms, interpretation of medical report findings) are sent back to the Application Layer.\")\n",
        "print(\"- The Application Layer formulates a human-readable text response based on the ML results and potentially information from the Knowledge Base.\")\n",
        "print(\"- This text response is passed to the voice assistant's TTS module.\")\n",
        "print(\"- The TTS module converts the text into spoken language for the user.\")\n",
        "print(\"- The voice assistant manages the dialogue flow, allowing for follow-up questions or clarifications.\")\n",
        "\n",
        "# 2. System Testing Levels and Types\n",
        "print(\"\\n2. System Testing Levels and Types:\")\n",
        "print(\"- **Unit Testing:** Testing individual components or modules in isolation (e.g., STT accuracy for a specific language, NLP intent recognition, a single function in the data preprocessing module, a specific layer in a neural network model).\")\n",
        "print(\"- **Integration Testing:** Testing the interaction and data flow between different modules (e.g., verifying that the STT output is correctly processed by the NLP module, ensuring the Application Layer correctly passes data to the ML Layer, testing the communication between the ML Inference Module and the response generation logic).\")\n",
        "print(\"- **System Testing:** Testing the complete, integrated system to verify that it meets specified requirements and functions as a whole (e.g., end-to-end test of a user asking a question and receiving a correct spoken response, testing the system's ability to process a full set of patient data).\")\n",
        "print(\"- **User Acceptance Testing (UAT):** Real-world testing with target users (healthcare professionals, patients) to evaluate usability, functionality, and whether the system meets their needs and expectations in a clinical or personal health context. This includes testing the voice assistant's naturalness and helpfulness.\")\n",
        "print(\"- **Performance/Load Testing:** Evaluating the system's responsiveness, stability, and resource usage under expected and peak load conditions (e.g., testing how many concurrent users the voice assistant can handle, the time taken for ML inference on complex data).\")\n",
        "print(\"- **Security Testing:** Assessing the system's vulnerability to attacks and ensuring patient data is protected (e.g., testing authentication, authorization, data encryption).\")\n",
        "\n",
        "# 3. Testing Machine Learning Model Accuracy within the Integrated System\n",
        "print(\"\\n3. Testing ML Model Accuracy within the Integrated System:\")\n",
        "print(\"- **End-to-End Data Flow Testing:** Simulate real-world data flow by feeding raw, unprocessed data (including voice recordings, unstructured text) into the system via the voice assistant or other ingestion points.\")\n",
        "print(\"- **Verification at Each Stage:** While the final output (e.g., risk assessment presented by the voice assistant) is the ultimate measure, intermediate steps should also be verified. For example, check if the transcribed text is accurate, if the extracted entities by NLP are correct, and if the features generated by the Data Processing Layer are as expected.\")\n",
        "print(\"- **Comparing System Output to Ground Truth:** For a set of test cases with known outcomes (ground truth diagnoses), compare the system's final output (e.g., the risk category or prediction communicated by the voice assistant) against the ground truth.\")\n",
        "print(\"- **Analyzing Edge Cases:** Test the system with challenging or unusual inputs, such as patients with complex medical histories, ambiguous voice queries, or incomplete data, to see how the ML model performs and how the system handles these situations.\")\n",
        "print(\"- **Monitoring Live Performance (Post-deployment):** Implement monitoring to track the ML model's performance on real-world data after deployment, comparing its predictions to confirmed diagnoses over time and identifying potential drift.\")\n",
        "\n",
        "# 4. Testing Voice Assistant Usability and Effectiveness\n",
        "print(\"\\n4. Testing Voice Assistant Usability and Effectiveness:\")\n",
        "print(\"- **Speech-to-Text (STT) Accuracy:** Test STT accuracy with diverse users speaking different languages, accents, dialects, and varying speech rates and clarity. Include testing in environments with background noise.\")\n",
        "print(\"- **Natural Language Understanding (NLU) Capabilities:** Test if the NLP module correctly understands user intent and extracts the right information for a wide range of medical queries and statements, including paraphrased or indirectly phrased inputs.\")\n",
        "print(\"- **Response Generation Quality:** Evaluate if the TTS module produces natural-sounding speech and if the generated text responses are accurate, clear, empathetic, and easy for users to understand, especially when conveying complex medical information or uncertainty.\")\n",
        "print(\"- **Multilingual Support Testing:** Systematically test all supported languages and language switching capabilities.\")\n",
        "print(\"- **Error Handling and Clarification:** Test how the voice assistant handles ambiguous queries, out-of-scope requests, or when it needs more information. Evaluate if its clarification prompts are helpful.\")\n",
        "print(\"- **User Experience (UX) Evaluation:** Conduct usability studies and gather feedback from target users on the overall interaction flow, ease of use, helpfulness, perceived trustworthiness, and satisfaction with the voice assistant.\")\n",
        "print(\"- **Dialogue Management Testing:** Ensure the assistant maintains context correctly throughout a conversation and can handle multi-turn interactions.\")\n",
        "\n",
        "# 5. Testing System Robustness and Error Handling\n",
        "print(\"\\n5. Testing System Robustness and Error Handling:\")\n",
        "print(\"- **Unexpected Inputs:** Test the system with malformed inputs, irrelevant queries, or data in unexpected formats.\")\n",
        "print(\"- **System Component Failures:** Simulate failures of individual components (e.g., database connection failure, ML model service downtime) to see how the system responds (graceful degradation, informative error messages).\")\n",
        "print(\"- **External Service Dependencies:** If the system relies on external APIs (e.g., for third-party STT/TTS services), test how it handles their unavailability or errors.\")\n",
        "print(\"- **Data Validation Errors:** Test how the system handles data that fails validation rules during the processing phase.\")\n",
        "print(\"- **Load and Stress Testing:** Push the system beyond its normal operating capacity to identify breaking points and performance bottlenecks.\")\n",
        "print(\"- **Security Vulnerabilities:** Actively test for common web and API vulnerabilities.\")\n",
        "\n",
        "# 6. Pilot Testing Plan\n",
        "print(\"\\n6. Pilot Testing Plan:\")\n",
        "print(\"- **Participant Recruitment:** Recruit a small, representative group of target users (e.g., a mix of healthcare providers and patients relevant to breast cancer screening/care).\")\n",
        "print(\"- **Defined Scope and Duration:** Clearly define the features and functionalities to be tested during the pilot and the duration of the pilot phase.\")\n",
        "print(\"- **Training and Onboarding:** Provide participants with necessary training or instructions on how to interact with the system.\")\n",
        "print(\"- **Data Collection Methods:** Implement mechanisms to collect detailed feedback (surveys, interviews, usability sessions), system logs (interaction transcripts, error logs, performance data), and potentially compare system outcomes with clinical records (with appropriate ethical approval).\")\n",
        "print(\"- **Iterative Feedback Loop:** Establish a process for rapidly collecting, analyzing, and acting on feedback to make improvements to the system during the pilot.\")\n",
        "print(\"- **Success Criteria:** Define clear criteria for evaluating the success of the pilot, such as minimum accuracy thresholds (both ML and voice assistant), user satisfaction scores, and identification of critical bugs.\")\n",
        "print(\"- **Reporting and Decision Making:** At the end of the pilot, analyze the collected data and feedback to inform decisions about wider deployment or further development.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Integration of ML Model and Voice Assistant:\n",
            "- The voice assistant's NLP module processes user input (transcribed text) to extract relevant medical information (symptoms, history, questions) and determine user intent.\n",
            "- This structured information is passed to the Application Layer.\n",
            "- The Application Layer, based on the user's intent, interacts with the Data Processing Layer to prepare the relevant patient data (structured + processed unstructured data).\n",
            "- The prepared data is then sent to the Machine Learning Layer's Model Inference Module.\n",
            "- The Model Inference Module loads and runs the appropriate trained ML model(s) on the data.\n",
            "- The results from the ML model(s) (e.g., risk assessment score, analysis of reported symptoms, interpretation of medical report findings) are sent back to the Application Layer.\n",
            "- The Application Layer formulates a human-readable text response based on the ML results and potentially information from the Knowledge Base.\n",
            "- This text response is passed to the voice assistant's TTS module.\n",
            "- The TTS module converts the text into spoken language for the user.\n",
            "- The voice assistant manages the dialogue flow, allowing for follow-up questions or clarifications.\n",
            "\n",
            "2. System Testing Levels and Types:\n",
            "- **Unit Testing:** Testing individual components or modules in isolation (e.g., STT accuracy for a specific language, NLP intent recognition, a single function in the data preprocessing module, a specific layer in a neural network model).\n",
            "- **Integration Testing:** Testing the interaction and data flow between different modules (e.g., verifying that the STT output is correctly processed by the NLP module, ensuring the Application Layer correctly passes data to the ML Layer, testing the communication between the ML Inference Module and the response generation logic).\n",
            "- **System Testing:** Testing the complete, integrated system to verify that it meets specified requirements and functions as a whole (e.g., end-to-end test of a user asking a question and receiving a correct spoken response, testing the system's ability to process a full set of patient data).\n",
            "- **User Acceptance Testing (UAT):** Real-world testing with target users (healthcare professionals, patients) to evaluate usability, functionality, and whether the system meets their needs and expectations in a clinical or personal health context. This includes testing the voice assistant's naturalness and helpfulness.\n",
            "- **Performance/Load Testing:** Evaluating the system's responsiveness, stability, and resource usage under expected and peak load conditions (e.g., testing how many concurrent users the voice assistant can handle, the time taken for ML inference on complex data).\n",
            "- **Security Testing:** Assessing the system's vulnerability to attacks and ensuring patient data is protected (e.g., testing authentication, authorization, data encryption).\n",
            "\n",
            "3. Testing ML Model Accuracy within the Integrated System:\n",
            "- **End-to-End Data Flow Testing:** Simulate real-world data flow by feeding raw, unprocessed data (including voice recordings, unstructured text) into the system via the voice assistant or other ingestion points.\n",
            "- **Verification at Each Stage:** While the final output (e.g., risk assessment presented by the voice assistant) is the ultimate measure, intermediate steps should also be verified. For example, check if the transcribed text is accurate, if the extracted entities by NLP are correct, and if the features generated by the Data Processing Layer are as expected.\n",
            "- **Comparing System Output to Ground Truth:** For a set of test cases with known outcomes (ground truth diagnoses), compare the system's final output (e.g., the risk category or prediction communicated by the voice assistant) against the ground truth.\n",
            "- **Analyzing Edge Cases:** Test the system with challenging or unusual inputs, such as patients with complex medical histories, ambiguous voice queries, or incomplete data, to see how the ML model performs and how the system handles these situations.\n",
            "- **Monitoring Live Performance (Post-deployment):** Implement monitoring to track the ML model's performance on real-world data after deployment, comparing its predictions to confirmed diagnoses over time and identifying potential drift.\n",
            "\n",
            "4. Testing Voice Assistant Usability and Effectiveness:\n",
            "- **Speech-to-Text (STT) Accuracy:** Test STT accuracy with diverse users speaking different languages, accents, dialects, and varying speech rates and clarity. Include testing in environments with background noise.\n",
            "- **Natural Language Understanding (NLU) Capabilities:** Test if the NLP module correctly understands user intent and extracts the right information for a wide range of medical queries and statements, including paraphrased or indirectly phrased inputs.\n",
            "- **Response Generation Quality:** Evaluate if the TTS module produces natural-sounding speech and if the generated text responses are accurate, clear, empathetic, and easy for users to understand, especially when conveying complex medical information or uncertainty.\n",
            "- **Multilingual Support Testing:** Systematically test all supported languages and language switching capabilities.\n",
            "- **Error Handling and Clarification:** Test how the voice assistant handles ambiguous queries, out-of-scope requests, or when it needs more information. Evaluate if its clarification prompts are helpful.\n",
            "- **User Experience (UX) Evaluation:** Conduct usability studies and gather feedback from target users on the overall interaction flow, ease of use, helpfulness, perceived trustworthiness, and satisfaction with the voice assistant.\n",
            "- **Dialogue Management Testing:** Ensure the assistant maintains context correctly throughout a conversation and can handle multi-turn interactions.\n",
            "\n",
            "5. Testing System Robustness and Error Handling:\n",
            "- **Unexpected Inputs:** Test the system with malformed inputs, irrelevant queries, or data in unexpected formats.\n",
            "- **System Component Failures:** Simulate failures of individual components (e.g., database connection failure, ML model service downtime) to see how the system responds (graceful degradation, informative error messages).\n",
            "- **External Service Dependencies:** If the system relies on external APIs (e.g., for third-party STT/TTS services), test how it handles their unavailability or errors.\n",
            "- **Data Validation Errors:** Test how the system handles data that fails validation rules during the processing phase.\n",
            "- **Load and Stress Testing:** Push the system beyond its normal operating capacity to identify breaking points and performance bottlenecks.\n",
            "- **Security Vulnerabilities:** Actively test for common web and API vulnerabilities.\n",
            "\n",
            "6. Pilot Testing Plan:\n",
            "- **Participant Recruitment:** Recruit a small, representative group of target users (e.g., a mix of healthcare providers and patients relevant to breast cancer screening/care).\n",
            "- **Defined Scope and Duration:** Clearly define the features and functionalities to be tested during the pilot and the duration of the pilot phase.\n",
            "- **Training and Onboarding:** Provide participants with necessary training or instructions on how to interact with the system.\n",
            "- **Data Collection Methods:** Implement mechanisms to collect detailed feedback (surveys, interviews, usability sessions), system logs (interaction transcripts, error logs, performance data), and potentially compare system outcomes with clinical records (with appropriate ethical approval).\n",
            "- **Iterative Feedback Loop:** Establish a process for rapidly collecting, analyzing, and acting on feedback to make improvements to the system during the pilot.\n",
            "- **Success Criteria:** Define clear criteria for evaluating the success of the pilot, such as minimum accuracy thresholds (both ML and voice assistant), user satisfaction scores, and identification of critical bugs.\n",
            "- **Reporting and Decision Making:** At the end of the pilot, analyze the collected data and feedback to inform decisions about wider deployment or further development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53d43c5a"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue printing the remaining parts of the testing plan, including ML accuracy testing details, voice assistant testing, robustness testing, and pilot testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ad85dc",
        "outputId": "484893c6-3849-4b38-bd19-aa492e70cb37"
      },
      "source": [
        "# 3. Testing Machine Learning Model Accuracy within the Integrated System (continued)\n",
        "print(\"- **Monitoring Live Performance (Post-deployment):** Implement monitoring to track the ML model's performance on real-world data after deployment, comparing its predictions to confirmed diagnoses over time and identifying potential drift.\")\n",
        "\n",
        "# 4. Testing Voice Assistant Usability and Effectiveness\n",
        "print(\"\\n4. Testing Voice Assistant Usability and Effectiveness:\")\n",
        "print(\"- **Speech-to-Text (STT) Accuracy:** Test STT accuracy with diverse users speaking different languages, accents, dialects, and varying speech rates and clarity. Include testing in environments with background noise.\")\n",
        "print(\"- **Natural Language Understanding (NLU) Capabilities:** Test if the NLP module correctly understands user intent and extracts the right information for a wide range of medical queries and statements, including paraphrased or indirectly phrased inputs.\")\n",
        "print(\"- **Response Generation Quality:** Evaluate if the TTS module produces natural-sounding speech and if the generated text responses are accurate, clear, empathetic, and easy for users to understand, especially when conveying complex medical information or uncertainty.\")\n",
        "print(\"- **Multilingual Support Testing:** Systematically test all supported languages and language switching capabilities.\")\n",
        "print(\"- **Error Handling and Clarification:** Test how the voice assistant handles ambiguous queries, out-of-scope requests, or when it needs more information. Evaluate if its clarification prompts are helpful.\")\n",
        "print(\"- **User Experience (UX) Evaluation:** Conduct usability studies and gather feedback from target users on the overall interaction flow, ease of use, helpfulness, perceived trustworthiness, and satisfaction with the voice assistant.\")\n",
        "print(\"- **Dialogue Management Testing:** Ensure the assistant maintains context correctly throughout a conversation and can handle multi-turn interactions.\")\n",
        "\n",
        "# 5. Testing System Robustness and Error Handling\n",
        "print(\"\\n5. Testing System Robustness and Error Handling:\")\n",
        "print(\"- **Unexpected Inputs:** Test the system with malformed inputs, irrelevant queries, or data in unexpected formats.\")\n",
        "print(\"- **System Component Failures:** Simulate failures of individual components (e.g., database connection failure, ML model service downtime) to see how the system responds (graceful degradation, informative error messages).\")\n",
        "print(\"- **External Service Dependencies:** If the system relies on external APIs (e.g., for third-party STT/TTS services), test how it handles their unavailability or errors.\")\n",
        "print(\"- **Data Validation Errors:** Test how the system handles data that fails validation rules during the processing phase.\")\n",
        "print(\"- **Load and Stress Testing:** Push the system beyond its normal operating capacity to identify breaking points and performance bottlenecks.\")\n",
        "print(\"- **Security Vulnerabilities:** Actively test for common web and API vulnerabilities.\")\n",
        "\n",
        "# 6. Pilot Testing Plan\n",
        "print(\"\\n6. Pilot Testing Plan:\")\n",
        "print(\"- **Participant Recruitment:** Recruit a small, representative group of target users (e.g., a mix of healthcare providers and patients relevant to breast cancer screening/care).\")\n",
        "print(\"- **Defined Scope and Duration:** Clearly define the features and functionalities to be tested during the pilot and the duration of the pilot phase.\")\n",
        "print(\"- **Training and Onboarding:** Provide participants with necessary training or instructions on how to interact with the system.\")\n",
        "print(\"- **Data Collection Methods:** Implement mechanisms to collect detailed feedback (surveys, interviews, usability sessions), system logs (interaction transcripts, error logs, performance data), and potentially compare system outcomes with clinical records (with appropriate ethical approval).\")\n",
        "print(\"- **Iterative Feedback Loop:** Establish a process for rapidly collecting, analyzing, and acting on feedback to make improvements to the system during the pilot.\")\n",
        "print(\"- **Success Criteria:** Define clear criteria for evaluating the success of the pilot, such as minimum accuracy thresholds (both ML and voice assistant), user satisfaction scores, and identification of critical bugs.\")\n",
        "print(\"- **Reporting and Decision Making:** At the end of the pilot, analyze the collected data and feedback to inform decisions about wider deployment or further development.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Monitoring Live Performance (Post-deployment):** Implement monitoring to track the ML model's performance on real-world data after deployment, comparing its predictions to confirmed diagnoses over time and identifying potential drift.\n",
            "\n",
            "4. Testing Voice Assistant Usability and Effectiveness:\n",
            "- **Speech-to-Text (STT) Accuracy:** Test STT accuracy with diverse users speaking different languages, accents, dialects, and varying speech rates and clarity. Include testing in environments with background noise.\n",
            "- **Natural Language Understanding (NLU) Capabilities:** Test if the NLP module correctly understands user intent and extracts the right information for a wide range of medical queries and statements, including paraphrased or indirectly phrased inputs.\n",
            "- **Response Generation Quality:** Evaluate if the TTS module produces natural-sounding speech and if the generated text responses are accurate, clear, empathetic, and easy for users to understand, especially when conveying complex medical information or uncertainty.\n",
            "- **Multilingual Support Testing:** Systematically test all supported languages and language switching capabilities.\n",
            "- **Error Handling and Clarification:** Test how the voice assistant handles ambiguous queries, out-of-scope requests, or when it needs more information. Evaluate if its clarification prompts are helpful.\n",
            "- **User Experience (UX) Evaluation:** Conduct usability studies and gather feedback from target users on the overall interaction flow, ease of use, helpfulness, perceived trustworthiness, and satisfaction with the voice assistant.\n",
            "- **Dialogue Management Testing:** Ensure the assistant maintains context correctly throughout a conversation and can handle multi-turn interactions.\n",
            "\n",
            "5. Testing System Robustness and Error Handling:\n",
            "- **Unexpected Inputs:** Test the system with malformed inputs, irrelevant queries, or data in unexpected formats.\n",
            "- **System Component Failures:** Simulate failures of individual components (e.g., database connection failure, ML model service downtime) to see how the system responds (graceful degradation, informative error messages).\n",
            "- **External Service Dependencies:** If the system relies on external APIs (e.g., for third-party STT/TTS services), test how it handles their unavailability or errors.\n",
            "- **Data Validation Errors:** Test how the system handles data that fails validation rules during the processing phase.\n",
            "- **Load and Stress Testing:** Push the system beyond its normal operating capacity to identify breaking points and performance bottlenecks.\n",
            "- **Security Vulnerabilities:** Actively test for common web and API vulnerabilities.\n",
            "\n",
            "6. Pilot Testing Plan:\n",
            "- **Participant Recruitment:** Recruit a small, representative group of target users (e.g., a mix of healthcare providers and patients relevant to breast cancer screening/care).\n",
            "- **Defined Scope and Duration:** Clearly define the features and functionalities to be tested during the pilot and the duration of the pilot phase.\n",
            "- **Training and Onboarding:** Provide participants with necessary training or instructions on how to interact with the system.\n",
            "- **Data Collection Methods:** Implement mechanisms to collect detailed feedback (surveys, interviews, usability sessions), system logs (interaction transcripts, error logs, performance data), and potentially compare system outcomes with clinical records (with appropriate ethical approval).\n",
            "- **Iterative Feedback Loop:** Establish a process for rapidly collecting, analyzing, and acting on feedback to make improvements to the system during the pilot.\n",
            "- **Success Criteria:** Define clear criteria for evaluating the success of the pilot, such as minimum accuracy thresholds (both ML and voice assistant), user satisfaction scores, and identification of critical bugs.\n",
            "- **Reporting and Decision Making:** At the end of the pilot, analyze the collected data and feedback to inform decisions about wider deployment or further development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e92698bf"
      },
      "source": [
        "## Consider ethical and privacy implications\n",
        "\n",
        "### Subtask:\n",
        "Address potential ethical and privacy concerns related to handling sensitive patient data and using a voice assistant in a healthcare context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d84ea7bb"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the key ethical considerations related to handling sensitive patient data, including bias, transparency, and over-reliance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b257db6",
        "outputId": "f3461b00-f340-4c67-df4b-5effb2a654d9"
      },
      "source": [
        "# 1. Key Ethical Considerations for Sensitive Patient Data\n",
        "print(\"1. Key Ethical Considerations for Handling Sensitive Patient Data:\")\n",
        "print(\"- **Bias in Data and Algorithms:** Machine learning models can perpetuate or even amplify biases present in the training data. In healthcare, this can lead to disparities in diagnosis or risk assessment for certain demographic groups (e.g., based on race, gender, socioeconomic status) if the data is not representative or if the model is not evaluated for fairness across subgroups.\")\n",
        "print(\"- **Transparency and Explainability (XAI):** It is often challenging to understand how complex ML models (like deep neural networks) arrive at a particular prediction or risk assessment. In a clinical setting, healthcare providers need to trust and understand the system's output. Lack of transparency makes it difficult to identify errors, understand the reasoning behind a prediction, and can hinder clinical adoption. Explainable AI (XAI) techniques are crucial here.\")\n",
        "print(\"- **Potential for Over-Reliance on the System:** Healthcare providers might over-rely on the system's predictions, potentially overlooking contradictory clinical evidence or losing their diagnostic skills. Patients might also place undue trust in the system's output, leading to anxiety or false reassurance. The system should be designed as a decision-support tool, not a replacement for clinical judgment.\")\n",
        "print(\"- **Accountability:** If the system makes an incorrect prediction that leads to harm, who is accountable? The developers, the healthcare institution, the prescribing doctor? Clear lines of responsibility need to be established.\")\n",
        "print(\"- **Informed Consent:** Patients must be fully informed about how their data will be used, the purpose of the system, its limitations, and how their privacy is protected. Consent for using their data and interacting with the voice assistant must be freely given and easily withdrawable.\")\n",
        "print(\"- **Equity and Access:** Ensure the system does not exacerbate existing health inequalities. This includes considering digital literacy, language barriers (addressed by the multilingual voice assistant, but performance must be equitable), and access to the necessary technology.\")\n",
        "print(\"- **Stigma and Discrimination:** Misuse of predictions (e.g., for insurance or employment) or data breaches could lead to stigma or discrimination against individuals with higher risk scores.\")\n",
        "print(\"- **Maintaining Human Oversight:** The system should be designed to keep human healthcare professionals in the loop for critical decisions and interpretation of results.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Key Ethical Considerations for Handling Sensitive Patient Data:\n",
            "- **Bias in Data and Algorithms:** Machine learning models can perpetuate or even amplify biases present in the training data. In healthcare, this can lead to disparities in diagnosis or risk assessment for certain demographic groups (e.g., based on race, gender, socioeconomic status) if the data is not representative or if the model is not evaluated for fairness across subgroups.\n",
            "- **Transparency and Explainability (XAI):** It is often challenging to understand how complex ML models (like deep neural networks) arrive at a particular prediction or risk assessment. In a clinical setting, healthcare providers need to trust and understand the system's output. Lack of transparency makes it difficult to identify errors, understand the reasoning behind a prediction, and can hinder clinical adoption. Explainable AI (XAI) techniques are crucial here.\n",
            "- **Potential for Over-Reliance on the System:** Healthcare providers might over-rely on the system's predictions, potentially overlooking contradictory clinical evidence or losing their diagnostic skills. Patients might also place undue trust in the system's output, leading to anxiety or false reassurance. The system should be designed as a decision-support tool, not a replacement for clinical judgment.\n",
            "- **Accountability:** If the system makes an incorrect prediction that leads to harm, who is accountable? The developers, the healthcare institution, the prescribing doctor? Clear lines of responsibility need to be established.\n",
            "- **Informed Consent:** Patients must be fully informed about how their data will be used, the purpose of the system, its limitations, and how their privacy is protected. Consent for using their data and interacting with the voice assistant must be freely given and easily withdrawable.\n",
            "- **Equity and Access:** Ensure the system does not exacerbate existing health inequalities. This includes considering digital literacy, language barriers (addressed by the multilingual voice assistant, but performance must be equitable), and access to the necessary technology.\n",
            "- **Stigma and Discrimination:** Misuse of predictions (e.g., for insurance or employment) or data breaches could lead to stigma or discrimination against individuals with higher risk scores.\n",
            "- **Maintaining Human Oversight:** The system should be designed to keep human healthcare professionals in the loop for critical decisions and interpretation of results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99064763"
      },
      "source": [
        "**Reasoning**:\n",
        "Detail critical privacy concerns when collecting, storing, and processing patient data, covering anonymization, secure storage, access control, and regulatory compliance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2cafc7",
        "outputId": "0778056b-39c5-48da-fdae-b7639b88042a"
      },
      "source": [
        "# 2. Critical Privacy Concerns for Patient Data\n",
        "print(\"\\n2. Critical Privacy Concerns for Patient Data:\")\n",
        "print(\"- **Data Collection and Minimization:** Collecting only the data strictly necessary for the breast cancer detection task. Over-collection increases privacy risks. Explicitly defining what data is collected and why.\")\n",
        "print(\"- **Data Anonymization/Pseudonymization:** Removing or obfuscating direct identifiers (like name, address, exact birth date) from the data. Pseudonymization replaces identifiers with artificial substitutes, allowing re-identification only with an additional key, which should be stored separately and securely. Full anonymization makes re-identification practically impossible.\")\n",
        "print(\"- **Secure Storage and Transmission:** Storing patient data in encrypted databases and file systems. Encrypting data both at rest (when stored) and in transit (when being transmitted between system components or over networks). Using secure protocols (like HTTPS) for all data transfer.\")\n",
        "print(\"- **Access Control:** Implementing strict access controls based on the principle of least privilege. Only authorized personnel (e.g., specific healthcare providers, data scientists working on the model) should have access to patient data, and only the minimum amount necessary for their role. Role-based access control (RBAC) is a standard approach.\")\n",
        "print(\"- **Compliance with Regulations (e.g., HIPAA, GDPR):** Adhering to relevant data protection and privacy regulations. HIPAA (Health Insurance Portability and Accountability Act) in the U.S. sets standards for protecting sensitive patient health information. GDPR (General Data Protection Regulation) in Europe provides comprehensive data protection rights for individuals. Compliance requires implementing specific technical and organizational measures, including obtaining proper consent, providing data access rights to individuals, and reporting breaches.\")\n",
        "print(\"- **Audit Trails:** Maintaining detailed logs of who accessed which data, when, and why. This is crucial for monitoring compliance and investigating potential breaches.\")\n",
        "print(\"- **Data Retention Policies:** Defining how long patient data will be stored and securely deleting data when it is no longer needed for the stated purpose.\")\n",
        "print(\"- **Third-Party Access:** Carefully vetting any third-party services or vendors used (e.g., cloud storage providers, external STT/TTS APIs) to ensure they meet the same high standards for data security and privacy and have appropriate data processing agreements in place.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Critical Privacy Concerns for Patient Data:\n",
            "- **Data Collection and Minimization:** Collecting only the data strictly necessary for the breast cancer detection task. Over-collection increases privacy risks. Explicitly defining what data is collected and why.\n",
            "- **Data Anonymization/Pseudonymization:** Removing or obfuscating direct identifiers (like name, address, exact birth date) from the data. Pseudonymization replaces identifiers with artificial substitutes, allowing re-identification only with an additional key, which should be stored separately and securely. Full anonymization makes re-identification practically impossible.\n",
            "- **Secure Storage and Transmission:** Storing patient data in encrypted databases and file systems. Encrypting data both at rest (when stored) and in transit (when being transmitted between system components or over networks). Using secure protocols (like HTTPS) for all data transfer.\n",
            "- **Access Control:** Implementing strict access controls based on the principle of least privilege. Only authorized personnel (e.g., specific healthcare providers, data scientists working on the model) should have access to patient data, and only the minimum amount necessary for their role. Role-based access control (RBAC) is a standard approach.\n",
            "- **Compliance with Regulations (e.g., HIPAA, GDPR):** Adhering to relevant data protection and privacy regulations. HIPAA (Health Insurance Portability and Accountability Act) in the U.S. sets standards for protecting sensitive patient health information. GDPR (General Data Protection Regulation) in Europe provides comprehensive data protection rights for individuals. Compliance requires implementing specific technical and organizational measures, including obtaining proper consent, providing data access rights to individuals, and reporting breaches.\n",
            "- **Audit Trails:** Maintaining detailed logs of who accessed which data, when, and why. This is crucial for monitoring compliance and investigating potential breaches.\n",
            "- **Data Retention Policies:** Defining how long patient data will be stored and securely deleting data when it is no longer needed for the stated purpose.\n",
            "- **Third-Party Access:** Carefully vetting any third-party services or vendors used (e.g., cloud storage providers, external STT/TTS APIs) to ensure they meet the same high standards for data security and privacy and have appropriate data processing agreements in place.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5003055d"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the specific ethical and privacy challenges introduced by the multilingual voice assistant, including equitable access, voice data privacy, and informed consent for voice interaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4bfcc6e",
        "outputId": "d2f89f8f-5bf2-44c4-970a-b3e38e16b65d"
      },
      "source": [
        "# 3. Ethical and Privacy Challenges with the Multilingual Voice Assistant\n",
        "print(\"\\n3. Ethical and Privacy Challenges with the Multilingual Voice Assistant:\")\n",
        "print(\"- **Equitable Access and Performance:** Ensuring the voice assistant performs equally well across all supported languages and dialects. Bias in STT and NLP models can lead to lower accuracy for certain language groups or accents, potentially resulting in unequal access to the system's benefits or inaccurate information being processed. This can exacerbate health disparities.\")\n",
        "print(\"- **Privacy of Voice Data Recordings:** Audio recordings of patient interactions are highly sensitive and contain potentially identifiable information (voice characteristics, background sounds). Storing these recordings raises significant privacy concerns. Ensuring these recordings are securely stored, accessed only when necessary (e.g., for model improvement with explicit consent), and promptly deleted or anonymized/pseudonymized is critical.\")\n",
        "print(\"- **Obtaining Informed Consent for Voice Interaction and Data Usage:** Explicitly informing users that their voice interactions are being recorded (if they are), how the recordings and transcribed text will be used, who will have access to them, and for how long. Obtaining clear, opt-in consent that is separate from general system usage terms. Making it easy for users to understand the consent process in their preferred language.\")\n",
        "print(\"- **Security of Voice Transmission:** Ensuring that the audio data transmitted from the user's device to the STT service (whether on-device or cloud-based) is encrypted and secure against interception.\")\n",
        "print(\"- **Misinterpretation and Communication Errors:** The voice assistant's understanding relies on STT and NLP accuracy. Misinterpreting a user's query, especially when discussing sensitive medical information or symptoms, can have serious consequences. This is particularly challenging across multiple languages and with medical terminology.\")\n",
        "print(\"- **User Trust and Comfort:** Patients, especially in a healthcare context, need to feel comfortable and trust interacting with a voice assistant about sensitive topics. Concerns about eavesdropping or how their voice data is used can erode this trust.\")\n",
        "print(\"- **Handling Emergencies or Distress:** The voice assistant needs to be designed to recognize cues of urgency or distress in a user's voice or language and have appropriate protocols to escalate to human assistance or emergency services, while still respecting privacy.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Ethical and Privacy Challenges with the Multilingual Voice Assistant:\n",
            "- **Equitable Access and Performance:** Ensuring the voice assistant performs equally well across all supported languages and dialects. Bias in STT and NLP models can lead to lower accuracy for certain language groups or accents, potentially resulting in unequal access to the system's benefits or inaccurate information being processed. This can exacerbate health disparities.\n",
            "- **Privacy of Voice Data Recordings:** Audio recordings of patient interactions are highly sensitive and contain potentially identifiable information (voice characteristics, background sounds). Storing these recordings raises significant privacy concerns. Ensuring these recordings are securely stored, accessed only when necessary (e.g., for model improvement with explicit consent), and promptly deleted or anonymized/pseudonymized is critical.\n",
            "- **Obtaining Informed Consent for Voice Interaction and Data Usage:** Explicitly informing users that their voice interactions are being recorded (if they are), how the recordings and transcribed text will be used, who will have access to them, and for how long. Obtaining clear, opt-in consent that is separate from general system usage terms. Making it easy for users to understand the consent process in their preferred language.\n",
            "- **Security of Voice Transmission:** Ensuring that the audio data transmitted from the user's device to the STT service (whether on-device or cloud-based) is encrypted and secure against interception.\n",
            "- **Misinterpretation and Communication Errors:** The voice assistant's understanding relies on STT and NLP accuracy. Misinterpreting a user's query, especially when discussing sensitive medical information or symptoms, can have serious consequences. This is particularly challenging across multiple languages and with medical terminology.\n",
            "- **User Trust and Comfort:** Patients, especially in a healthcare context, need to feel comfortable and trust interacting with a voice assistant about sensitive topics. Concerns about eavesdropping or how their voice data is used can erode this trust.\n",
            "- **Handling Emergencies or Distress:** The voice assistant needs to be designed to recognize cues of urgency or distress in a user's voice or language and have appropriate protocols to escalate to human assistance or emergency services, while still respecting privacy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9590584"
      },
      "source": [
        "**Reasoning**:\n",
        "Propose mitigation strategies and safeguards to address the identified ethical and privacy concerns, covering technical, policy, and user-centric approaches.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c44f28f",
        "outputId": "c62b7cd4-ca97-474b-a87d-1e813e4a6649"
      },
      "source": [
        "# 4. Mitigation Strategies and Safeguards\n",
        "print(\"\\n4. Mitigation Strategies and Safeguards:\")\n",
        "print(\"- **Technical Measures:**\")\n",
        "print(\"  - **Differential Privacy:** Adding noise to the data or model outputs during training or inference to protect individual data points while allowing for aggregate analysis. This makes it harder to infer information about any single individual.\")\n",
        "print(\"  - **Secure Multi-Party Computation (SMPC):** Allows multiple parties to jointly compute a function over their inputs while keeping those inputs private. Could be used for collaborative model training without sharing raw data.\")\n",
        "print(\"  - **Homomorphic Encryption:** Allows computation on encrypted data without decrypting it, potentially enabling analysis or model inference on encrypted patient data.\")\n",
        "print(\"  - **Federated Learning:** Training models on decentralized data residing on local devices or in different institutions without centralizing the raw data, enhancing privacy.\")\n",
        "print(\"  - **Robust Anonymization/Pseudonymization Techniques:** Implementing advanced techniques to minimize the risk of re-identification, including k-anonymity, l-diversity, and t-closeness.\")\n",
        "print(\"  - **End-to-End Encryption:** Encrypting data from the point of collection (e.g., the user's device for voice) to storage and processing.\")\n",
        "print(\"  - **Secure Enclaves:** Using hardware-based secure enclaves for processing sensitive data or model inference, providing a trusted execution environment.\")\n",
        "print(\"  - **Auditable Access Logs:** Implementing immutable and comprehensive logs of all data access and system interactions for auditing and monitoring.\")\n",
        "print(\"  - **Regular Security Audits and Penetration Testing:** Proactively identifying and addressing vulnerabilities in the system.\")\n",
        "print(\"- **Policy Measures:**\")\n",
        "print(\"  - **Clear Data Governance Policies:** Establishing transparent policies on data collection, usage, storage, retention, and sharing. Clearly defining roles and responsibilities for data handling.\")\n",
        "print(\"  - **Robust Consent Frameworks:** Designing a clear, granular, and easily understandable consent process for both data usage and voice interaction. Allowing users to easily withdraw consent.\")\n",
        "print(\"  - **Compliance with Regulations:** Ensuring ongoing adherence to HIPAA, GDPR, and any other relevant local or international data privacy regulations. Regularly updating policies and procedures to reflect regulatory changes.\")\n",
        "print(\"  - **Bias Detection and Mitigation Policies:** Implementing processes to regularly audit data and models for bias and having strategies in place to mitigate identified biases (e.g., collecting more representative data, using fairness-aware algorithms, post-processing model outputs).\")\n",
        "print(\"  - **Responsible AI Guidelines:** Adopting internal guidelines for the responsible development and deployment of AI in healthcare, emphasizing fairness, transparency, and safety.\")\n",
        "print(\"  - **Third-Party Agreements:** Ensuring all contracts with third-party vendors handling patient data include strict data protection and confidentiality clauses.\")\n",
        "print(\"- **User-Centric Approaches:**\")\n",
        "print(\"  - **User Control over Data:** Providing users with dashboards or interfaces to view what data is collected about them, how it is used, and allowing them to request corrections or deletion (in compliance with regulations).\")\n",
        "print(\"  - **Clear Communication about System Capabilities and Limitations:** Transparently explaining to users what the system does, what it doesn't do, its potential accuracy levels, and emphasizing that it is a support tool, not a definitive diagnostic tool.\")\n",
        "print(\"  - **Explainable AI (XAI) for Users and Providers:** Developing ways to explain the system's predictions or risk assessments in an understandable manner for both healthcare professionals and patients.\")\n",
        "print(\"  - **Opt-out Options:** Providing users with options to opt-out of certain data collection or system features if feasible without compromising core functionality.\")\n",
        "print(\"  - **Multilingual Support and Cultural Sensitivity:** Ensuring the voice assistant is not only technically multilingual but also culturally sensitive in its interactions and language use.\")\n",
        "print(\"  - **Easy Access to Human Support:** Making it clear and easy for users to switch from the voice assistant to a human healthcare professional when needed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Mitigation Strategies and Safeguards:\n",
            "- **Technical Measures:**\n",
            "  - **Differential Privacy:** Adding noise to the data or model outputs during training or inference to protect individual data points while allowing for aggregate analysis. This makes it harder to infer information about any single individual.\n",
            "  - **Secure Multi-Party Computation (SMPC):** Allows multiple parties to jointly compute a function over their inputs while keeping those inputs private. Could be used for collaborative model training without sharing raw data.\n",
            "  - **Homomorphic Encryption:** Allows computation on encrypted data without decrypting it, potentially enabling analysis or model inference on encrypted patient data.\n",
            "  - **Federated Learning:** Training models on decentralized data residing on local devices or in different institutions without centralizing the raw data, enhancing privacy.\n",
            "  - **Robust Anonymization/Pseudonymization Techniques:** Implementing advanced techniques to minimize the risk of re-identification, including k-anonymity, l-diversity, and t-closeness.\n",
            "  - **End-to-End Encryption:** Encrypting data from the point of collection (e.g., the user's device for voice) to storage and processing.\n",
            "  - **Secure Enclaves:** Using hardware-based secure enclaves for processing sensitive data or model inference, providing a trusted execution environment.\n",
            "  - **Auditable Access Logs:** Implementing immutable and comprehensive logs of all data access and system interactions for auditing and monitoring.\n",
            "  - **Regular Security Audits and Penetration Testing:** Proactively identifying and addressing vulnerabilities in the system.\n",
            "- **Policy Measures:**\n",
            "  - **Clear Data Governance Policies:** Establishing transparent policies on data collection, usage, storage, retention, and sharing. Clearly defining roles and responsibilities for data handling.\n",
            "  - **Robust Consent Frameworks:** Designing a clear, granular, and easily understandable consent process for both data usage and voice interaction. Allowing users to easily withdraw consent.\n",
            "  - **Compliance with Regulations:** Ensuring ongoing adherence to HIPAA, GDPR, and any other relevant local or international data privacy regulations. Regularly updating policies and procedures to reflect regulatory changes.\n",
            "  - **Bias Detection and Mitigation Policies:** Implementing processes to regularly audit data and models for bias and having strategies in place to mitigate identified biases (e.g., collecting more representative data, using fairness-aware algorithms, post-processing model outputs).\n",
            "  - **Responsible AI Guidelines:** Adopting internal guidelines for the responsible development and deployment of AI in healthcare, emphasizing fairness, transparency, and safety.\n",
            "  - **Third-Party Agreements:** Ensuring all contracts with third-party vendors handling patient data include strict data protection and confidentiality clauses.\n",
            "- **User-Centric Approaches:**\n",
            "  - **User Control over Data:** Providing users with dashboards or interfaces to view what data is collected about them, how it is used, and allowing them to request corrections or deletion (in compliance with regulations).\n",
            "  - **Clear Communication about System Capabilities and Limitations:** Transparently explaining to users what the system does, what it doesn't do, its potential accuracy levels, and emphasizing that it is a support tool, not a definitive diagnostic tool.\n",
            "  - **Explainable AI (XAI) for Users and Providers:** Developing ways to explain the system's predictions or risk assessments in an understandable manner for both healthcare professionals and patients.\n",
            "  - **Opt-out Options:** Providing users with options to opt-out of certain data collection or system features if feasible without compromising core functionality.\n",
            "  - **Multilingual Support and Cultural Sensitivity:** Ensuring the voice assistant is not only technically multilingual but also culturally sensitive in its interactions and language use.\n",
            "  - **Easy Access to Human Support:** Making it clear and easy for users to switch from the voice assistant to a human healthcare professional when needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59e3eb57"
      },
      "source": [
        "**Reasoning**:\n",
        "Emphasize the importance of ongoing monitoring, auditing, and ethical review of the system.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96a47ba9",
        "outputId": "7f3e66ab-c773-4252-9741-a044983e94ef"
      },
      "source": [
        "# 5. Importance of Ongoing Monitoring, Auditing, and Ethical Review\n",
        "print(\"\\n5. Importance of Ongoing Monitoring, Auditing, and Ethical Review:\")\n",
        "print(\"Developing and deploying the system is not the end; continuous effort is required to maintain ethical standards and privacy:\")\n",
        "print(\"- **Ongoing Performance Monitoring:** Continuously monitor the performance of the ML models on live data to detect any drift in accuracy or emerging biases, particularly across different demographic or language groups.\")\n",
        "print(\"- **Regular Security Audits and Penetration Testing:** Conduct periodic security audits and penetration testing to identify and address new vulnerabilities as the system and threat landscape evolve.\")\n",
        "print(\"- **Audit Log Review:** Regularly review audit trails to detect any unauthorized access or suspicious activity related to patient data.\")\n",
        "print(\"- **Post-Market Surveillance for Bias:** Actively monitor for evidence of the system leading to disparate outcomes or perpetuating biases in real-world clinical use.\")\n",
        "print(\"- **User Feedback Collection and Analysis:** Establish channels for collecting feedback from both patients and healthcare providers regarding their experience with the system, including usability, trustworthiness, and any ethical or privacy concerns they encounter.\")\n",
        "print(\"- **Regular Ethical Review Board Consultations:** Engage with internal or external ethics review boards to assess the system's ongoing ethical implications, especially when making updates or changes to features or data usage.\")\n",
        "print(\"- **Adapting to Evolving Regulations and Best Practices:** Stay informed about changes in data privacy regulations (like HIPAA, GDPR) and emerging best practices in AI ethics and security, and update the system and policies accordingly.\")\n",
        "print(\"- **Model Retraining and Validation:** Periodically retrain the ML models on new, diverse data to maintain accuracy and address potential data drift. Re-evaluate the models rigorously for fairness and performance on all relevant subgroups.\")\n",
        "print(\"- **Transparency in Updates:** Clearly communicate any significant changes to the system's functionality, data usage, or privacy policies to users.\")\n",
        "print(\"Ongoing monitoring, auditing, and ethical review are crucial for building and maintaining a trustworthy and responsible breast cancer detection system that respects patient privacy and promotes equitable healthcare.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Importance of Ongoing Monitoring, Auditing, and Ethical Review:\n",
            "Developing and deploying the system is not the end; continuous effort is required to maintain ethical standards and privacy:\n",
            "- **Ongoing Performance Monitoring:** Continuously monitor the performance of the ML models on live data to detect any drift in accuracy or emerging biases, particularly across different demographic or language groups.\n",
            "- **Regular Security Audits and Penetration Testing:** Conduct periodic security audits and penetration testing to identify and address new vulnerabilities as the system and threat landscape evolve.\n",
            "- **Audit Log Review:** Regularly review audit trails to detect any unauthorized access or suspicious activity related to patient data.\n",
            "- **Post-Market Surveillance for Bias:** Actively monitor for evidence of the system leading to disparate outcomes or perpetuating biases in real-world clinical use.\n",
            "- **User Feedback Collection and Analysis:** Establish channels for collecting feedback from both patients and healthcare providers regarding their experience with the system, including usability, trustworthiness, and any ethical or privacy concerns they encounter.\n",
            "- **Regular Ethical Review Board Consultations:** Engage with internal or external ethics review boards to assess the system's ongoing ethical implications, especially when making updates or changes to features or data usage.\n",
            "- **Adapting to Evolving Regulations and Best Practices:** Stay informed about changes in data privacy regulations (like HIPAA, GDPR) and emerging best practices in AI ethics and security, and update the system and policies accordingly.\n",
            "- **Model Retraining and Validation:** Periodically retrain the ML models on new, diverse data to maintain accuracy and address potential data drift. Re-evaluate the models rigorously for fairness and performance on all relevant subgroups.\n",
            "- **Transparency in Updates:** Clearly communicate any significant changes to the system's functionality, data usage, or privacy policies to users.\n",
            "Ongoing monitoring, auditing, and ethical review are crucial for building and maintaining a trustworthy and responsible breast cancer detection system that respects patient privacy and promotes equitable healthcare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **with NN** bold text\n",
        "\n"
      ],
      "metadata": {
        "id": "gpr0HSL1dWH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "breast_cancer_dataset=sklearn.datasets.load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "rnWiVjdP0z3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4eJJlSUdx5c",
        "outputId": "a31446e7-e2a2-4f77-8b49-72e26bcfd8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52e13f50"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The system will utilize both structured data (age, gender, family history, previous biopsies, hormonal factors, lifestyle choices) and unstructured data (doctor's notes, pathology reports, radiology reports, audio recordings from voice assistant interactions).\n",
        "*   Data collection will involve integrating with electronic health records (EHRs) and laboratory information systems, as well as processing voice and potentially image data.\n",
        "*   Data preprocessing strategies are designed to handle missing values and inconsistencies in structured data, and to convert unstructured text and audio data into numerical formats suitable for machine learning models through techniques like tokenization, vectorization (TF-IDF, embeddings), and feature extraction (MFCCs).\n",
        "*   The machine learning component will likely employ hybrid or multi-modal neural networks, ensemble methods, or specialized models (like Transformers for text and CNNs for images/audio) that can process and combine insights from different data types.\n",
        "*   The multilingual voice assistant will function through a pipeline involving Speech-to-Text (STT), Natural Language Processing (NLP) for intent recognition and information extraction, and Text-to-Speech (TTS) for generating responses, with a focus on multilingual capabilities at each stage.\n",
        "*   The system architecture is designed with distinct layers for Data, Data Processing, Machine Learning, Voice Assistant, and Application, with the Application Layer acting as a central coordinator between the voice interface and the backend processing.\n",
        "*   Model training and evaluation will involve consolidating features from all data types, handling class imbalance, splitting data into training, validation, and testing sets, and using metrics like Precision, Recall, F1-score, and AUC, along with validation techniques such as stratified k-fold cross-validation.\n",
        "*   System testing will cover multiple levels, including unit, integration, system, user acceptance, performance, and security testing, with specific plans for evaluating the integrated ML model accuracy and the voice assistant's usability and effectiveness.\n",
        "*   Significant ethical and privacy considerations include addressing bias in data and algorithms, ensuring transparency and explainability of ML models, protecting the privacy of sensitive patient data (including voice recordings) through anonymization, encryption, and access controls, and complying with regulations like HIPAA and GDPR.\n",
        "*   Mitigation strategies for ethical and privacy concerns involve technical measures (e.g., differential privacy, federated learning), policy measures (e.g., clear data governance, robust consent), and user-centric approaches (e.g., user control over data, clear communication).\n",
        "*   Ongoing monitoring, auditing, and ethical review are deemed crucial for maintaining the system's trustworthiness and responsible operation post-deployment.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Prioritize the development and rigorous testing of the multilingual STT and NLP components to ensure equitable performance across diverse language speakers, as this is foundational for the voice assistant's effectiveness and ethical deployment.\n",
        "*   Develop a detailed plan for implementing the proposed data security and privacy measures, including specific technologies for encryption, anonymization, and access control, to ensure compliance with healthcare regulations and build user trust.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame=pd.DataFrame(breast_cancer_dataset.data,columns=breast_cancer_dataset.feature_names)\n",
        "data_frame.head()\n",
        "data_frame['label']=breast_cancer_dataset.target\n",
        "#data_frame.info()\n",
        "# for missssssing value check any record or data be unfilled\n",
        "data_frame.isnull().sum()\n",
        "# describe\n",
        "#defines the in each column ''' data analysis'''' gives average value of each column shows for each column the mean value, standard value, min , max etc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IytX5nXyPr2e",
        "outputId": "22e55a9d-63b3-4b7a-e3e7-8170e3489ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "label                      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean symmetry</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal dimension error</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst radius</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst texture</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst perimeter</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst area</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst smoothness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst compactness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concavity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concave points</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst symmetry</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for the different cases of Beningn and Malignant case\n",
        "data_frame['label'].value_counts()\n",
        "data_frame.groupby('label').mean()\n",
        "X=data_frame.drop(columns='label',axis=1)\n",
        "Y=data_frame['label']\n",
        "#features(input) and target(output)\n",
        "# splitting the data into training data and testing data\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=2)\n"
      ],
      "metadata": {
        "id": "elTZDRWJSErl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(3)\n",
        "from tensorflow import keras           #tensorflow as backend and pytorch for keras\n",
        "#setting up the layers of Neural Network   # rectified linear unit\n",
        "model=keras.Sequential([keras.layers.Flatten(input_shape=(30,)) ,keras.layers.Dense(20,activation='relu'), keras.layers.Dense(2,activation='sigmoid')])\n",
        "#compiling the neural network\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZtlIyRDV8DB",
        "outputId": "36b0e08f-3962-4f63-cb52-0fb380cbd765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the training data\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#training the neural network similar to machine learning\n",
        "history=model.fit(X_train_std,Y_train,validation_split=0.1,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Q-tAomgIat",
        "outputId": "aa2360ec-7556-4bc1-a9c4-3bf9b30082d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5466 - loss: 0.6995 - val_accuracy: 0.8913 - val_loss: 0.4388\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8733 - loss: 0.4379 - val_accuracy: 0.9565 - val_loss: 0.2951\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9168 - loss: 0.3051 - val_accuracy: 0.9565 - val_loss: 0.2183\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.2352 - val_accuracy: 0.9565 - val_loss: 0.1752\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9462 - loss: 0.1939 - val_accuracy: 0.9783 - val_loss: 0.1484\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9482 - loss: 0.1673 - val_accuracy: 0.9783 - val_loss: 0.1301\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9551 - loss: 0.1483 - val_accuracy: 0.9783 - val_loss: 0.1166\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9573 - loss: 0.1339 - val_accuracy: 0.9783 - val_loss: 0.1059\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1225 - val_accuracy: 0.9783 - val_loss: 0.0974\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1131 - val_accuracy: 0.9783 - val_loss: 0.0906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "X_train_std=scaler.fit_transform(X_train)\n",
        "X_test_std=scaler.transform(X_test)\n",
        "print(X_train_std)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data','validation data'],loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "r-h4vnxYaEjl",
        "outputId": "a93f21d6-01c4-4610-cc11-823f7b7b703f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.01330339  1.7757658  -0.01491962 ... -0.13236958 -1.08014517\n",
            "  -0.03527943]\n",
            " [-0.8448276  -0.6284278  -0.87702746 ... -1.11552632 -0.85773964\n",
            "  -0.72098905]\n",
            " [ 1.44755936  0.71180168  1.47428816 ...  0.87583964  0.4967602\n",
            "   0.46321706]\n",
            " ...\n",
            " [-0.46608541 -1.49375484 -0.53234924 ... -1.32388956 -1.02997851\n",
            "  -0.75145272]\n",
            " [-0.50025764 -1.62161319 -0.527814   ... -0.0987626   0.35796577\n",
            "  -0.43906159]\n",
            " [ 0.96060511  1.21181916  1.00427242 ...  0.8956983  -1.23064515\n",
            "   0.50697397]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data','validation data'],loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ZOgIr4uuiLRy",
        "outputId": "fef55e4c-5ee3-46a4-a7a7-fe640173c477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(X_test_std,Y_test)\n",
        "print(\"Test Accuracy:\",accuracy)\n",
        "print(X_test_std.shape)\n",
        "print(X_test_std[0])\n",
        "#classificaition\n",
        "Y_pred=model.predict(X_test_std)\n",
        "print(Y_pred.shape)\n",
        "print(Y_pred[0])\n",
        "print(X_test_std)\n",
        "\n",
        "# model.predict() gives the prediction probability of each class for that data point\n",
        "#argmax funciton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v24sPttwjmuL",
        "outputId": "4ec28d5a-35d3-47a4-a290-4c9f91d606d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.1271 \n",
            "Test Accuracy: 0.9561403393745422\n",
            "(114, 30)\n",
            "[-0.04462793 -1.41612656 -0.05903514 -0.16234067  2.0202457  -0.11323672\n",
            "  0.18500609  0.47102419  0.63336386  0.26335737  0.53209124  2.62763999\n",
            "  0.62351167  0.11405261  1.01246781  0.41126289  0.63848593  2.88971815\n",
            " -0.41675911  0.74270853 -0.32983699 -1.67435595 -0.36854552 -0.38767294\n",
            "  0.32655007 -0.74858917 -0.54689089 -0.18278004 -1.23064515 -0.6268286 ]\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "(114, 2)\n",
            "[0.32508066 0.5027861 ]\n",
            "[[-0.04462793 -1.41612656 -0.05903514 ... -0.18278004 -1.23064515\n",
            "  -0.6268286 ]\n",
            " [ 0.24583601 -0.06219797  0.21802678 ...  0.54129749  0.11047691\n",
            "   0.0483572 ]\n",
            " [-1.26115925 -0.29051645 -1.26499659 ... -1.35138617  0.269338\n",
            "  -0.28231213]\n",
            " ...\n",
            " [ 0.72709489  0.45836817  0.75277276 ...  1.46701686  1.19909344\n",
            "   0.65319961]\n",
            " [ 0.25437907  1.33054477  0.15659489 ... -1.29043534 -2.22561725\n",
            "  -1.59557344]\n",
            " [ 0.84100232 -0.06676434  0.8929529  ...  2.15137705  0.35629355\n",
            "   0.37459546]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEv97XzSCbF",
        "outputId": "2019801b-da64-414e-d83b-07d947b3d4f6"
      },
      "source": [
        "Y_pred_labels=[int(np.argmax(i)) for i in Y_pred]\n",
        "print(Y_pred_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input\n",
        "input_data=(13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.139,0.2479,1.025,11.24,0.00555,0.01892,0.02561,0.0155,0.02754,0.002251,15.11,19.26,99.71,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)\n",
        "input_data_as_numpy_array=np.asarray(input_data)\n",
        "# reshape the numpy array as we are predicting for one data point\n",
        "input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)\n",
        "#standardizing the input data\n",
        "input_data_std=scaler.transform(input_data_reshaped)\n",
        "prediction=model.predict(input_data_std)\n",
        "print(prediction)\n",
        "prediction_label=[np.argmax(prediction)]\n",
        "print(prediction_label)\n",
        "if(prediction_label[0]==0):\n",
        "  print(\"The tumor is Malignant( breast cancer detected.)\")\n",
        "else:\n",
        "  print(\"The tumor is Benign . you don't have to worry you are safe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3ExLwRv8ubQ",
        "outputId": "10580e78-e02d-4666-981e-f267fba72dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "[[0.18448883 0.88905776]]\n",
            "[np.int64(1)]\n",
            "The tumor is Benign . you don't have to worry you are safe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}